{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW_12_Kaggle.ipynb","provenance":[],"mount_file_id":"1QFaOLppAqbU5HlhMxC8Q0A0guvGr6siA","authorship_tag":"ABX9TyO/m7co1z82g0AUhIVygdqi"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QuogTNwxxbgO","colab_type":"text"},"source":["# Installs and Imports"]},{"cell_type":"code","metadata":{"id":"v4Aa1V4ulhaf","colab_type":"code","outputId":"1a633964-a8fa-4003-f7df-00d6e36dd484","executionInfo":{"status":"ok","timestamp":1586987016664,"user_tz":300,"elapsed":3351,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["! pip install geopandas"],"execution_count":160,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.7.0)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n","Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.3)\n","Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.6.0)\n","Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.13.post1)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n","Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.1)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yiu-iTc8ltkr","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","from shapely.geometry import Point\n","import os\n","import tensorflow as tf\n","from tqdm import tqdm\n","from sklearn.utils import shuffle\n","from sklearn.metrics import mean_squared_log_error\n","\n","from datetime import datetime\n","from datetime import timedelta\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","\n","import copy"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1VgX5Wy9xiYD","colab_type":"text"},"source":["# Global Variables"]},{"cell_type":"code","metadata":{"id":"30v5aaPhlviO","colab_type":"code","colab":{}},"source":["data_dir = \"drive/My Drive/Classes/CSCE_5933_Deep_Learning/HW_12_Kaggle/Data/\"\n","train_file = \"%strain.csv\"%data_dir\n","extra_data_file = \"%senriched_covid_19_week_2.csv\"%data_dir\n","test_file = \"%stest.csv\"%data_dir\n","num_trends = 2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjEEXhwKxmI6","colab_type":"text"},"source":["# Load and Process Training Data"]},{"cell_type":"code","metadata":{"id":"jSlB_SS_lycB","colab_type":"code","colab":{}},"source":["# Load base data.\n","train_df = gpd.read_file(train_file)\n","train_df[\"ConfirmedCases\"] = train_df[\"ConfirmedCases\"].astype(\"float\")\n","train_df[\"Fatalities\"] = train_df[\"Fatalities\"].astype(\"float\")\n","#The country_region got modified in the enriched dataset by @optimo, \n","# so we have to apply the same change to this Dataframe to facilitate the merge.\n","train_df[\"Country_Region\"] = [ row.Country_Region.replace(\"'\",\"\").strip(\" \") if row.Province_State==\"\" else str(row.Country_Region+\"_\"+row.Province_State).replace(\"'\",\"\").strip(\" \") for idx,row in train_df.iterrows()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CC93ZvFPylBl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"f9d561ea-c76b-458d-b525-0f11c8c2e775","executionInfo":{"status":"ok","timestamp":1586987020383,"user_tz":300,"elapsed":6963,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}}},"source":["train_df.head()"],"execution_count":164,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Province_State</th>\n","      <th>Country_Region</th>\n","      <th>Date</th>\n","      <th>ConfirmedCases</th>\n","      <th>Fatalities</th>\n","      <th>geometry</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-22</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-23</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-24</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-26</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Id Province_State Country_Region  ... ConfirmedCases  Fatalities  geometry\n","0  1                   Afghanistan  ...            0.0         0.0      None\n","1  2                   Afghanistan  ...            0.0         0.0      None\n","2  3                   Afghanistan  ...            0.0         0.0      None\n","3  4                   Afghanistan  ...            0.0         0.0      None\n","4  5                   Afghanistan  ...            0.0         0.0      None\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":164}]},{"cell_type":"code","metadata":{"id":"fR6_1O13l55Z","colab_type":"code","outputId":"c7768865-47cb-4396-ccfb-d68a83cc8fc5","executionInfo":{"status":"ok","timestamp":1586987022183,"user_tz":300,"elapsed":8724,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["#Still using the enriched data from week 2 as there is everything required for the model's training\n","extra_data_df = gpd.read_file(extra_data_file)\n","extra_data_df[\"Country_Region\"] = [country_name.replace(\"'\", \"\") for country_name in extra_data_df[\"Country_Region\"]]\n","extra_data_df[\"restrictions\"] = extra_data_df[\"restrictions\"].astype(\"int\")\n","extra_data_df[\"quarantine\"] = extra_data_df[\"quarantine\"].astype(\"int\")\n","extra_data_df[\"schools\"] = extra_data_df[\"schools\"].astype(\"int\")\n","extra_data_df[\"total_pop\"] = extra_data_df[\"total_pop\"].astype(\"float\")\n","extra_data_df[\"density\"] = extra_data_df[\"density\"].astype(\"float\")\n","extra_data_df[\"hospibed\"] = extra_data_df[\"hospibed\"].astype(\"float\")\n","extra_data_df[\"lung\"] = extra_data_df[\"lung\"].astype(\"float\")\n","extra_data_df[\"total_pop\"] = extra_data_df[\"total_pop\"]/max(extra_data_df[\"total_pop\"])\n","extra_data_df[\"density\"] = extra_data_df[\"density\"]/max(extra_data_df[\"density\"])\n","extra_data_df[\"hospibed\"] = extra_data_df[\"hospibed\"]/max(extra_data_df[\"hospibed\"])\n","extra_data_df[\"lung\"] = extra_data_df[\"lung\"]/max(extra_data_df[\"lung\"])\n","extra_data_df[\"age_100+\"] = extra_data_df[\"age_100+\"].astype(\"float\")\n","extra_data_df[\"age_100+\"] = extra_data_df[\"age_100+\"]/max(extra_data_df[\"age_100+\"])\n","\n","extra_data_df = extra_data_df[[\"Country_Region\", \n","                               \"Date\", \n","                               \"restrictions\", \n","                               \"quarantine\", \n","                               \"schools\", \n","                               \"hospibed\", \n","                               \"lung\", \n","                               \"total_pop\", \n","                               \"density\", \n","                               \"age_100+\"\n","                               ]]\n","extra_data_df.head()"],"execution_count":165,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country_Region</th>\n","      <th>Date</th>\n","      <th>restrictions</th>\n","      <th>quarantine</th>\n","      <th>schools</th>\n","      <th>hospibed</th>\n","      <th>lung</th>\n","      <th>total_pop</th>\n","      <th>density</th>\n","      <th>age_100+</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-22</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-23</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-24</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-25</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Country_Region        Date  restrictions  ...  total_pop   density  age_100+\n","0    Afghanistan  2020-01-22             0  ...   0.027046  0.002278  0.001411\n","1    Afghanistan  2020-01-23             0  ...   0.027046  0.002278  0.001411\n","2    Afghanistan  2020-01-24             0  ...   0.027046  0.002278  0.001411\n","3    Afghanistan  2020-01-25             0  ...   0.027046  0.002278  0.001411\n","4    Afghanistan  2020-01-26             0  ...   0.027046  0.002278  0.001411\n","\n","[5 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"c6NTL38ryQOx","colab_type":"code","outputId":"23bfacc3-64b1-43b1-9343-cf45deedc741","executionInfo":{"status":"ok","timestamp":1586987023552,"user_tz":300,"elapsed":10068,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["# Drop columns that have changing values. (quarantine, schools, restrictions)\n","changes = set()\n","for cr in extra_data_df[\"Country_Region\"].unique():\n","    tmp = extra_data_df.loc[extra_data_df[\"Country_Region\"] == cr]\n","    for c in tmp.columns:\n","        if c == \"Date\":\n","            continue\n","        u = tmp[c].unique()\n","        if len(u) > 1:\n","            changes.add(c)\n","for c in changes:\n","    del extra_data_df[c]\n","print([x for x in changes])\n","extra_data_df.head()"],"execution_count":166,"outputs":[{"output_type":"stream","text":["['quarantine', 'restrictions', 'schools']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country_Region</th>\n","      <th>Date</th>\n","      <th>hospibed</th>\n","      <th>lung</th>\n","      <th>total_pop</th>\n","      <th>density</th>\n","      <th>age_100+</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-22</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-23</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-24</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-25</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Afghanistan</td>\n","      <td>2020-01-26</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Country_Region        Date  hospibed      lung  total_pop   density  age_100+\n","0    Afghanistan  2020-01-22  0.036232  0.329191   0.027046  0.002278  0.001411\n","1    Afghanistan  2020-01-23  0.036232  0.329191   0.027046  0.002278  0.001411\n","2    Afghanistan  2020-01-24  0.036232  0.329191   0.027046  0.002278  0.001411\n","3    Afghanistan  2020-01-25  0.036232  0.329191   0.027046  0.002278  0.001411\n","4    Afghanistan  2020-01-26  0.036232  0.329191   0.027046  0.002278  0.001411"]},"metadata":{"tags":[]},"execution_count":166}]},{"cell_type":"code","metadata":{"id":"FbOcuobMy1D_","colab_type":"code","outputId":"59d91789-1cfb-442a-91ae-52adc0fb31cd","executionInfo":{"status":"ok","timestamp":1586987023698,"user_tz":300,"elapsed":10196,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":299}},"source":["# Merge extra data with training data.\n","train_df = train_df.merge(extra_data_df, how=\"left\", on=[\"Country_Region\", \"Date\"]).drop_duplicates()\n","train_df.head()"],"execution_count":167,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Province_State</th>\n","      <th>Country_Region</th>\n","      <th>Date</th>\n","      <th>ConfirmedCases</th>\n","      <th>Fatalities</th>\n","      <th>geometry</th>\n","      <th>hospibed</th>\n","      <th>lung</th>\n","      <th>total_pop</th>\n","      <th>density</th>\n","      <th>age_100+</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-22</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-23</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-24</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td></td>\n","      <td>Afghanistan</td>\n","      <td>2020-01-26</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Id Province_State Country_Region  ... total_pop   density  age_100+\n","0  1                   Afghanistan  ...  0.027046  0.002278  0.001411\n","1  2                   Afghanistan  ...  0.027046  0.002278  0.001411\n","2  3                   Afghanistan  ...  0.027046  0.002278  0.001411\n","3  4                   Afghanistan  ...  0.027046  0.002278  0.001411\n","4  5                   Afghanistan  ...  0.027046  0.002278  0.001411\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":167}]},{"cell_type":"code","metadata":{"id":"f2D9VeIp22YE","colab_type":"code","outputId":"6079cea0-653f-4932-b709-a1f31251a04b","executionInfo":{"status":"ok","timestamp":1586987025595,"user_tz":300,"elapsed":12075,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["# Fill countries/regions not in the extra data with median values.\n","median_pop = np.median(extra_data_df.total_pop)\n","median_hospibed = np.median(extra_data_df.hospibed)\n","median_density = np.median(extra_data_df.density)\n","median_lung = np.median(extra_data_df.lung)\n","median_centenarian_pop = np.median(extra_data_df[\"age_100+\"])\n","#need to replace that with a joint using Pandas\n","print(\"The missing countries/region are:\")\n","missing = []\n","for country_region in train_df.Country_Region.unique():\n","    if extra_data_df.query(\"Country_Region=='\"+country_region+\"'\").empty:\n","        print(country_region)\n","        \n","        train_df.loc[train_df[\"Country_Region\"]==country_region, \"total_pop\"] = median_pop\n","        train_df.loc[train_df[\"Country_Region\"]==country_region, \"hospibed\"] = median_hospibed\n","        train_df.loc[train_df[\"Country_Region\"]==country_region, \"density\"] = median_density\n","        train_df.loc[train_df[\"Country_Region\"]==country_region, \"lung\"] = median_lung\n","        train_df.loc[train_df[\"Country_Region\"]==country_region, \"age_100+\"] = median_centenarian_pop\n","        # train_df.loc[train_df[\"Country_Region\"]==country_region,\"restrictions\"] = 0\n","        # train_df.loc[train_df[\"Country_Region\"]==country_region,\"quarantine\"] = 0\n","        # train_df.loc[train_df[\"Country_Region\"]==country_region,\"schools\"] = 0"],"execution_count":168,"outputs":[{"output_type":"stream","text":["The missing countries/region are:\n","Botswana\n","Burma\n","Burundi\n","Canada_Northwest Territories\n","Canada_Yukon\n","France_Saint Pierre and Miquelon\n","Kosovo\n","MS Zaandam\n","Malawi\n","Netherlands_Bonaire, Sint Eustatius and Saba\n","Sao Tome and Principe\n","Sierra Leone\n","South Sudan\n","United Kingdom_Anguilla\n","United Kingdom_British Virgin Islands\n","United Kingdom_Falkland Islands (Malvinas)\n","United Kingdom_Turks and Caicos Islands\n","West Bank and Gaza\n","Western Sahara\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ywkIu2rm3ZSP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"ddbcd01e-712c-41ee-9afe-5278a4ab0bf4","executionInfo":{"status":"ok","timestamp":1586988166113,"user_tz":300,"elapsed":422,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}}},"source":["train_df.columns"],"execution_count":183,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n","       'Fatalities', 'geometry', 'hospibed', 'lung', 'total_pop', 'density',\n","       'age_100+'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":183}]},{"cell_type":"code","metadata":{"id":"3HYKEHDbt7Bx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":390},"outputId":"0e2b56ef-58a3-486f-8f80-c28c3a832294","executionInfo":{"status":"error","timestamp":1586988655121,"user_tz":300,"elapsed":418,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}}},"source":["from sklearn import linear_model\n","\n","for country in train_df.Country_Region.unique():\n","    for province in train_df.query(f\"Country_Region=='{country}'\").Province_State.unique():\n","        df = pd.DataFrame(train_df.query(f\"Country_Region=='{country}' and Province_State=='{province}'\"))\n","        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n","        df = df.sort_values(by=\"Date\")\n","        df = df[[\"hospibed\",\n","                 \"lung\", \n","                 \"total_pop\", \n","                 \"density\", \n","                 \"age_100+\",\n","                 \"ConfirmedCases\", \n","                 \"Fatalities\", \n","                 ]]\n","        y = df[[\"ConfirmedCases\", \"Fatalities\"]].values\n","        cols = list(df.columns)\n","        x = df.values\n","        for i, row in enumerate(x):\n","            if i == 0:\n","                continue\n","            x[i][cols.index(\"ConfirmedCases\")] = x[i-1][cols.index(\"ConfirmedCases\")]\n","            x[i][cols.index(\"Fatalities\")] = x[i-1][cols.index(\"Fatalities\")]\n","\n","        reg = linear_model.LinearRegression().fit(x, y)\n","        print(reg.score(x, y))\n","\n","        # linear_model.LogisticRegression\n","\n"],"execution_count":185,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-185-4adc6caff16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fatalities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fatalities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 492\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."]}]},{"cell_type":"code","metadata":{"id":"AQAKxa6BuRdo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"outputId":"ff0c7592-baff-42b6-b51a-1e74539415f3","executionInfo":{"status":"ok","timestamp":1586988758719,"user_tz":300,"elapsed":380,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}}},"source":["df"],"execution_count":187,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hospibed</th>\n","      <th>lung</th>\n","      <th>total_pop</th>\n","      <th>density</th>\n","      <th>age_100+</th>\n","      <th>ConfirmedCases</th>\n","      <th>Fatalities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.036232</td>\n","      <td>0.329191</td>\n","      <td>0.027046</td>\n","      <td>0.002278</td>\n","      <td>0.001411</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>83 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["    hospibed      lung  total_pop  ...  age_100+  ConfirmedCases  Fatalities\n","0   0.036232  0.329191   0.027046  ...  0.001411             0.0         0.0\n","1   0.036232  0.329191   0.027046  ...  0.001411             0.0         0.0\n","2   0.036232  0.329191   0.027046  ...  0.001411             0.0         0.0\n","3   0.036232  0.329191   0.027046  ...  0.001411             0.0         0.0\n","4   0.036232  0.329191   0.027046  ...  0.001411             0.0         0.0\n","..       ...       ...        ...  ...       ...             ...         ...\n","78       NaN       NaN        NaN  ...       NaN             0.0         0.0\n","79       NaN       NaN        NaN  ...       NaN             0.0         0.0\n","80       NaN       NaN        NaN  ...       NaN             0.0         0.0\n","81       NaN       NaN        NaN  ...       NaN             0.0         0.0\n","82       NaN       NaN        NaN  ...       NaN             0.0         0.0\n","\n","[83 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":187}]},{"cell_type":"code","metadata":{"id":"U92yLOgKAZ0R","colab_type":"code","colab":{}},"source":["# Cleanup.\n","del extra_data_df\n","del changes\n","del tmp\n","del missing"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkgJLlmel-o6","colab_type":"code","colab":{}},"source":["# Create dataframe to store trends.\n","trend_df = pd.DataFrame(columns={\"infection_trend\", \n","                                 \"fatality_trend\", \n","                                 \"quarantine_trend\", \n","                                 \"school_trend\", \n","                                 \"total_population\", \n","                                 \"expected_cases\", \n","                                 \"expected_fatalities\"\n","                                 })"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWI5JQTimCE2","colab_type":"code","colab":{}},"source":["# Drop all dates not in March.\n","train_df = train_df.query(\"Date>'2020-02-29'and Date<'2020-04-01'\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-3I6jpK4Rj3","colab_type":"code","colab":{}},"source":["days_in_month = len(list(train_df[\"Date\"].unique()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eX7KTrWj5jve","colab_type":"code","outputId":"e1ad322b-8209-4a99-8517-b28dd4aacf1d","executionInfo":{"status":"ok","timestamp":1586976149006,"user_tz":300,"elapsed":65543,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["# Build trends.\n","trends_all = {}\n","trend_lengths = [x for x in range(days_in_month) if x%5 == 0 and x != 0]\n","trend_lengths.append(days_in_month)\n","iters = len(trend_lengths)*len(list(train_df[\"Country_Region\"].unique()))\n","count = 0\n","\n","for d, days_in_sequence in enumerate(trend_lengths):\n","    trend_list = []\n","    for c, country in enumerate(train_df.Country_Region.unique()):\n","        for province in train_df.query(f\"Country_Region=='{country}'\").Province_State.unique():\n","            province_df = train_df.query(f\"Country_Region=='{country}' and Province_State=='{province}'\")\n","            \n","            #I added a quick hack to double the number of sequences\n","            #Warning: This will later create a minor leakage from the \n","            # training set into the validation set.\n","            for i in range(0,len(province_df),int(days_in_sequence/3)):\n","                if i+days_in_sequence<=len(province_df):\n","                    #prepare all the temporal inputs\n","                    infection_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].ConfirmedCases.values]\n","                    fatality_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].Fatalities.values]\n","                    # restriction_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].restrictions.values]\n","                    # quarantine_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].quarantine.values]\n","                    # school_trend = [float(x) for x in province_df[i:i+days_in_sequence-1].schools.values]\n","\n","                    #preparing all the demographic inputs\n","                    total_population = float(province_df.iloc[i].total_pop)\n","                    density = float(province_df.iloc[i].density)\n","                    hospibed = float(province_df.iloc[i].hospibed)\n","                    lung = float(province_df.iloc[i].lung)\n","                    centenarian_pop = float(province_df.iloc[i][\"age_100+\"])\n","\n","                    expected_cases = float(province_df.iloc[i+days_in_sequence-1].ConfirmedCases)\n","                    expected_fatalities = float(province_df.iloc[i+days_in_sequence-1].Fatalities)\n","\n","                    trend_list.append({\"infection_trend\":infection_trend,\n","                                    \"fatality_trend\":fatality_trend,\n","                                    # \"restriction_trend\":restriction_trend,\n","                                    # \"quarantine_trend\":quarantine_trend,\n","                                    # \"school_trend\":school_trend,\n","                                    \"demographic_inputs\":[total_population,density,hospibed,lung,centenarian_pop],\n","                                    \"expected_cases\":expected_cases,\n","                                    \"expected_fatalities\":expected_fatalities})\n","        count += 1\n","        if count % 100 == 0 or count == iters:\n","            print(\"%d/%d\"%(count, iters))\n","    trends_all.update({days_in_sequence: pd.DataFrame(trend_list)})\n","# trend_df = pd.DataFrame(trend_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100/2191\n","200/2191\n","300/2191\n","400/2191\n","500/2191\n","600/2191\n","700/2191\n","800/2191\n","900/2191\n","1000/2191\n","1100/2191\n","1200/2191\n","1300/2191\n","1400/2191\n","1500/2191\n","1600/2191\n","1700/2191\n","1800/2191\n","1900/2191\n","2000/2191\n","2100/2191\n","2191/2191\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C9XIyeld_fNR","colab_type":"code","colab":{}},"source":[" # Format trends and shuffle data.\n"," for trend_l in trends_all:\n","    trends_all[trend_l][\"temporal_inputs\"] = [np.asarray([trends[\"infection_trend\"], \n","                                                          trends[\"fatality_trend\"], \n","                                                        #   trends[\"restriction_trend\"], \n","                                                        #   trends[\"quarantine_trend\"], \n","                                                        #   trends[\"school_trend\"] , \n","                                                          ]) for idx, trends in trends_all[trend_l].iterrows()]\n","    trends_all[trend_l] = shuffle(trends_all[trend_l])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yELIjJYBrOB","colab_type":"code","colab":{}},"source":["# Drop all but 25 sequences where the number of cases stays at 0.\n","# i=0\n","# temp_df = pd.DataFrame()\n","# for idx,row in trend_df.iterrows():\n","#     if sum(row.infection_trend)>0:\n","#         temp_df = temp_df.append(row)\n","#     else:\n","#         if i<25:\n","#             temp_df = temp_df.append(row)\n","#             i+=1\n","# trend_df = temp_df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjwg9WOoB7Am","colab_type":"code","colab":{}},"source":["# Split dataset(s) into training and validation.\n","training_percentage = 0.9\n","\n","for trend_l in trends_all:\n","    sequence_length = trend_l - 1\n","    trend_df = trends_all[trend_l]\n","\n","    training_item_count = int(len(trend_df)*training_percentage)\n","    validation_item_count = len(trend_df)-int(len(trend_df)*training_percentage)\n","    training_df = trend_df[:training_item_count]\n","    validation_df = trend_df[training_item_count:]\n","\n","    X_temporal_train = np.asarray(np.transpose(np.reshape(np.asarray([np.asarray(x) for x in training_df[\"temporal_inputs\"].values]), (training_item_count, num_trends, sequence_length)), (0, 2, 1) )).astype(np.float32)\n","    X_demographic_train = np.asarray([np.asarray(x) for x in training_df[\"demographic_inputs\"]]).astype(np.float32)\n","    Y_cases_train = np.asarray([np.asarray(x) for x in training_df[\"expected_cases\"]]).astype(np.float32)\n","    Y_fatalities_train = np.asarray([np.asarray(x) for x in training_df[\"expected_fatalities\"]]).astype(np.float32)\n","\n","    X_temporal_val = np.asarray(np.transpose(np.reshape(np.asarray([np.asarray(x) for x in validation_df[\"temporal_inputs\"]]), (validation_item_count, num_trends, sequence_length)), (0, 2, 1)) ).astype(np.float32)\n","    X_demographic_val = np.asarray([np.asarray(x) for x in validation_df[\"demographic_inputs\"]]).astype(np.float32)\n","    Y_cases_val = np.asarray([np.asarray(x) for x in validation_df[\"expected_cases\"]]).astype(np.float32)\n","    Y_fatalities_val = np.asarray([np.asarray(x) for x in validation_df[\"expected_fatalities\"]]).astype(np.float32)\n","\n","    trends_all[trend_l] = {\"train\": {\"X_temporal_train\": X_temporal_train, \n","                                    \"X_demographic_train\": X_demographic_train, \n","                                    \"Y_cases_train\": Y_cases_train, \n","                                    \"Y_fatalities_train\": Y_fatalities_train, \n","                                    }, \n","                        \"val\": {\"X_temporal_val\": X_temporal_val, \n","                                \"X_demographic_val\": X_demographic_val, \n","                                \"Y_cases_val\": Y_cases_val, \n","                                \"Y_fatalities_val\": Y_fatalities_val, \n","                                }, \n","                        }"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j0qWhz1CD4UU","colab_type":"text"},"source":["# Build Model"]},{"cell_type":"code","metadata":{"id":"TQHp5jacD6hE","colab_type":"code","outputId":"90a1cec5-aa63-4e8d-bbcb-2e97f99c6c26","executionInfo":{"status":"ok","timestamp":1586976417026,"user_tz":300,"elapsed":6627,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# Build model structures.\n","models_all = []\n","for train_l in trends_all:\n","    print(train_l)\n","    sequence_length = train_l - 1\n","\n","    #temporal input branch\n","    temporal_input_layer = Input(shape=(sequence_length, num_trends))\n","    main_rnn_layer = layers.LSTM(64, return_sequences=True, recurrent_dropout=0.2)(temporal_input_layer)\n","\n","    #demographic input branch\n","    demographic_input_layer = Input(shape=(num_trends))\n","    demographic_dense = layers.Dense(16)(demographic_input_layer)\n","    demographic_dropout = layers.Dropout(0.2)(demographic_dense)\n","\n","    #cases output branch\n","    rnn_c = layers.LSTM(32)(main_rnn_layer)\n","    merge_c = layers.Concatenate(axis=-1)([rnn_c,demographic_dropout])\n","    dense_c = layers.Dense(128)(merge_c)\n","    dropout_c = layers.Dropout(0.3)(dense_c)\n","    cases = layers.Dense(1, activation=layers.LeakyReLU(alpha=0.1),name=\"cases\")(dropout_c)\n","\n","    #fatality output branch\n","    rnn_f = layers.LSTM(32)(main_rnn_layer)\n","    merge_f = layers.Concatenate(axis=-1)([rnn_f,demographic_dropout])\n","    dense_f = layers.Dense(128)(merge_f)\n","    dropout_f = layers.Dropout(0.3)(dense_f)\n","    fatalities = layers.Dense(1, activation=layers.LeakyReLU(alpha=0.1), name=\"fatalities\")(dropout_f)\n","\n","\n","    model = Model([temporal_input_layer, demographic_input_layer], [cases,fatalities])\n","\n","    model.summary()\n","    print()\n","\n","    models_all.append(model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["5\n","10\n","15\n","20\n","25\n","30\n","31\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Id3YR4HKKHHM","colab_type":"code","colab":{}},"source":["# Build callbacks and compile models.\n","for i, trend_l in enumerate(trends_all):\n","    trends_all[trend_l].update({\"model\": models_all[i]})\n","    \n","    trends_all[trend_l][\"callbacks\"] = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n","                                        EarlyStopping(monitor='val_loss', patience=20),\n","                                        ModelCheckpoint(filepath='trend_%d/best_model.h5'%trend_l, monitor='val_loss', save_best_only=True)]\n","    trends_all[trend_l][\"model\"].compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVQEX0beN8Pa","colab_type":"code","outputId":"cd232aa0-af52-4e12-fb12-30cbd27e2671","executionInfo":{"status":"ok","timestamp":1586977339536,"user_tz":300,"elapsed":366,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(trends_all[5][\"callbacks\"])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[<tensorflow.python.keras.callbacks.ReduceLROnPlateau object at 0x7f623dfa8da0>, <tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f623dfa8240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f623dfa8c88>]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZuX7fiAvH3Lg","colab_type":"code","outputId":"d5c19a56-03a2-49e3-88e1-b0eb7bdaf8bf","executionInfo":{"status":"error","timestamp":1586977268230,"user_tz":300,"elapsed":685,"user":{"displayName":"Mica Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKXHcqzSUcoMDkbPtJrWlpdkkU2LO3kJyPfSrM=s64","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/","height":785}},"source":["for trend_l in trends_all:\n","    trends_all[\"history\"] = trends_all[trend_l][\"model\"].fit([trends_all[trend_l][\"train\"][\"X_temporal_train\"], \n","                                                             trends_all[trend_l][\"train\"][\"X_demographic_train\"]], \n","                                                             [trends_all[trend_l][\"train\"][\"Y_cases_train\"], \n","                                                             trends_all[trend_l][\"train\"][\"Y_fatalities_train\"]], \n","                                                             epochs = 250, \n","                                                             batch_size = 16, \n","                                                             validation_data=([trends_all[trend_l][\"val\"][\"X_temporal_val\"], \n","                                                                               trends_all[trend_l][\"val\"][\"X_demographic_val\"]],  \n","                                                                               [trends_all[trend_l][\"val\"][\"Y_cases_val\"], \n","                                                                               trends_all[trend_l][\"val\"][\"Y_fatalities_val\"]]), \n","                                                             callbacks=trends_all[trend_l][\"callbacks\"])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/250\n","WARNING:tensorflow:Model was constructed with shape (None, 2) for input Tensor(\"input_48:0\", shape=(None, 2), dtype=float32), but it was called on an input with incompatible shape (None, 5).\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-144-9f3162ebcc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                            [trends_all[trend_l][\"val\"][\"Y_cases_val\"], \n\u001b[1;32m     11\u001b[0m                             trends_all[trend_l][\"val\"][\"Y_fatalities_val\"]]), \n\u001b[0;32m---> 12\u001b[0;31m           callbacks=trends_all[trend_l][\"callbacks\"])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:465 train_step  **\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:714 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:883 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_69 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape [None, 5]\n"]}]}]}