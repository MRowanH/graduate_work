{"cells":[{"cell_type":"markdown","metadata":{"id":"wXQo1QrjsoiR"},"source":["# Experiments Information"]},{"cell_type":"markdown","metadata":{"id":"cBCIuLUEsrxQ"},"source":["### Data\n","\n","Dataset split: shuffle by seed=42, then split\n","\n","* Source Activities: Downstairs, Jogging, Upstairs, Walking\n","\n","    * Train: 80%\n","    * Val: 10%\n","    * Test: 10%\n","\n","* Target Activites: Sitting, Standing\n","\n","    * Train: 80%\n","    * Val: 10%\n","    * Test: 10%"]},{"cell_type":"markdown","metadata":{"id":"ieXCB7nWmXJZ"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RO82r-F7mS4X"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import pickle\n","import tensorflow as tf\n","import warnings\n","\n","from copy import deepcopy\n","from google.colab import drive\n","from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix, roc_auc_score\n","from tabulate import tabulate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8W3n5uBzdHN"},"outputs":[],"source":["# Supress warnings\n","warnings.resetwarnings()\n","warnings.simplefilter('ignore', pd.core.common.SettingWithCopyWarning)\n","# tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","source":["# Global Variables"],"metadata":{"id":"zIjoxAEL3gUV"}},{"cell_type":"code","source":["data = {}\n","data_dir = \"/content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Datasets/\"    # Mica\n","dirs = {\"source\": data_dir + \"UCI_UC_k_means_preprocessed/\", \"target\": data_dir + \"WISDM_UC_k_means_preprocessed/\"}\n","source_labels = set()\n","target_labels = set()"],"metadata":{"id":"E3J9-UwX3iBL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2R_bHegmanw"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLM8qzQzzYGn"},"outputs":[],"source":["if not os.path.exists(\"drive/\"):\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EgQ2JR_oF9J"},"outputs":[],"source":["# View shapes\n","def view_data_shapes(data):\n","    for k1 in data:\n","        print(k1, \"=============================================\")\n","        for k2 in data[k1]:\n","            print(k2, \"---------------------------------------------\")\n","            for k3 in data[k1][k2]:\n","                print(k3, \" \", data[k1][k2][k3].shape)\n","            print()\n","        print()"]},{"cell_type":"code","source":["# Iterate\n","for k1 in [\"source\", \"target\"]:\n","    data.update({k1: {}})\n","    for k2 in [\"train\", \"val\", \"test\"]:\n","        data[k1].update({k2: {}})\n","        for k3 in [\"x\", \"y\"]: #, \"x_shaped\"]:\n","\n","            # Get source and target files\n","            f_name = dirs[k1] + k1 + \"_\" + k2 + \"_\" + k3\n","            x = None\n","            if k3 == \"x_shaped\":\n","                with open(f_name + \".pickle\", \"rb\") as file:\n","                    x = pickle.load(file)\n","            else:\n","                x = pd.read_csv(f_name + \".csv\")\n","            data[k1][k2].update({k3: x})\n","\n","            # Get label values\n","            if k3 == \"y\":\n","                for x in list(data[k1][k2][k3][\"label\"].unique()):\n","                    if k1 == \"source\":\n","                        source_labels.add(x)\n","                    elif k1 == \"target\":\n","                        target_labels.add(x)\n","\n","view_data_shapes(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytWlXO-Rye8D","executionInfo":{"status":"ok","timestamp":1668458207837,"user_tz":360,"elapsed":3017,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}},"outputId":"66f0e435-d2dc-4556-a200-0ba545acf34b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["source =============================================\n","train ---------------------------------------------\n","x   (16478, 561)\n","y   (16478, 1)\n","\n","val ---------------------------------------------\n","x   (2060, 561)\n","y   (2060, 1)\n","\n","test ---------------------------------------------\n","x   (2060, 561)\n","y   (2060, 1)\n","\n","\n","target =============================================\n","train ---------------------------------------------\n","x   (3819, 405)\n","y   (3819, 1)\n","\n","val ---------------------------------------------\n","x   (477, 405)\n","y   (477, 1)\n","\n","test ---------------------------------------------\n","x   (478, 405)\n","y   (478, 1)\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"aS3SgliY6e-5"},"source":["# Models"]},{"cell_type":"markdown","metadata":{"id":"4Jwt0KC7wkgZ"},"source":["## Single Model Handler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTnKaxexwnVh"},"outputs":[],"source":["class ModelHandler():\n","    \n","    def __init__(self, name, source_labels, target_labels, checkpoint_path=\"checkpoints/\", checkpoint_file_name=\"cp.ckpt\"):\n","        self.model_name = name\n","        self.source_lables = source_labels\n","        self.target_labels = target_labels\n","        self.checkpoint_path = checkpoint_path\n","        self.checkpoint_file_name = checkpoint_file_name\n","        self.cp_paths = {}\n","        self.cp_callbacks = {}\n","        self.hist = {}\n","            \n","    # Build model ==============================================================\n","    def build_model(self, model_type, input_shape, n_labels=6, learning_rate=0.001, metrics=[\"accuracy\"]):\n","        if model_type not in [\"dense\", \"conv\"]:\n","            print(model_type, \"is an invalid model type. Please enter a value in [\\\"dense\\\", \\\"conv\\\"].\")\n","        self.model_type = model_type\n","        self.input_shape = input_shape\n","        self.n_labels = n_labels\n","        self.learning_rate = learning_rate\n","        self.metrics = metrics\n","\n","        model = tf.keras.Sequential([tf.keras.layers.Input(shape=input_shape)])\n","        \n","        # Build dense model\n","        if model_type == \"dense\":\n","            model = self.build_dense_model(model)\n","\n","        # Build cnn model\n","        elif model_type == \"conv\":\n","            model = self.build_conv_model(model, input_shape)\n","\n","        model.add(tf.keras.layers.Dense(n_labels, activation=\"softmax\"))\n","        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n","                      metrics=metrics\n","                      )\n","        self.model = model\n","    \n","    def build_transfer_model(self, train_layers, input_shape, n_labels=6, metrics=[\"accuracy\"]):\n","        tmp = tf.keras.Sequential([tf.keras.layers.Input(shape=input_shape)])\n","        \n","        # Build dense model\n","        if self.model_type == \"dense\":\n","            tmp = self.build_dense_model(tmp)\n","\n","        # Build cnn model\n","        elif self.model_type == \"conv\":\n","            tmp = self.build_conv_model(tmp, input_shape)\n","\n","        tmp.add(tf.keras.layers.Dense(n_labels, activation=\"softmax\"))\n","\n","        for new_layer, layer in zip(tmp.layers[1:-train_layers], self.model.layers[1:-train_layers]):\n","            new_layer.set_weights(layer.get_weights())\n","            new_layer.trainable = False\n","            \n","        tmp.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n","                    metrics=metrics\n","                    )\n","        \n","        self.model = deepcopy(tmp)\n","    \n","    def build_dense_model(self, model):\n","        model.add(tf.keras.layers.Dense(1024, activation=\"relu\"))\n","        model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n","        model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n","        model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n","        model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n","        model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n","        model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n","        # model.add(tf.keras.layers.Dense(405, activation=\"relu\"))\n","        # model.add(tf.keras.layers.Dense(202, activation=\"relu\"))\n","        # model.add(tf.keras.layers.Dense(101, activation=\"relu\"))\n","        return model\n","\n","    def build_conv_model(self, model, input_shape):\n","        model.add(tf.keras.layers.Conv2D(32, kernel_size=(1, 1),\n","                                                  activation='relu',\n","                                                  input_shape=input_shape\n","                                                  ))\n","        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n","        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","        model.add(tf.keras.layers.Dropout(0.25))\n","        model.add(tf.keras.layers.Flatten())\n","        model.add(tf.keras.layers.Dense(128, activation='relu'))\n","        model.add(tf.keras.layers.Dropout(0.5))\n","        return model\n","        \n","    # Train model ==============================================================\n","\n","    # Checkpointing ------------------------------------------------------------\n","    def setup_checkpointing(self, experiment_level):\n","\n","        # Paths\n","        if experiment_level not in self.cp_paths:\n","            self.cp_paths.update({experiment_level: \"%s%s\"%(self.checkpoint_path, self.checkpoint_file_name)})\n","        if not os.path.exists(self.cp_paths[experiment_level]):\n","            os.makedirs(self.cp_paths[experiment_level])\n","\n","        # Callbacks\n","        if experiment_level not in self.cp_callbacks:\n","            self.cp_callbacks.update({experiment_level: tf.keras.callbacks.ModelCheckpoint(filepath=self.cp_paths[experiment_level],\n","                                                                                           save_weights_only=True,\n","                                                                                           verbose=1, \n","                                                                                           save_freq=\"epoch\",\n","                                                                                           save_best_only=True\n","                                                                                           )\n","                                      })\n","    \n","    # Training -----------------------------------------------------------------\n","    def train_model(self, experiment_level, train_x, train_y, val_x, val_y, epochs=10):\n","\n","        # Setup checkpoints\n","        self.setup_checkpointing(experiment_level)\n","\n","        # Update history dictionary\n","        if experiment_level not in self.hist:\n","            self.hist.update({experiment_level: None})\n","\n","        # Train\n","        self.hist[experiment_level] = self.model.fit(train_x, train_y, \n","                                                     validation_data=(val_x, val_y), \n","                                                     epochs=epochs, \n","                                                     callbacks=[self.cp_callbacks[experiment_level]]\n","                                                     )\n","        \n","        # Load best\n","        self.model.load_weights(self.cp_paths[experiment_level])\n","\n","    # Evaluate =================================================================\n","    def evaluate(self, test_x, test_y, verbose=True):\n","        preds =  self.model.predict(test_x)\n","        preds_select = np.apply_along_axis(np.argmax, 1, preds)\n","        true = [y[0] for y in test_y.values]\n","\n","        loss, acc = self.model.evaluate(test_x, test_y, verbose=2)\n","        scores = precision_recall_fscore_support(true, preds_select, average='macro')\n","        pre = scores[0]\n","        re = scores[1]\n","        f1 = scores[2]\n","        auc = np.nan\n","        try:\n","            auc = roc_auc_score(true, preds, multi_class=\"ovo\")\n","        except:\n","            auc = np.nan\n","\n","        report = classification_report(true, preds_select)\n","        cm = None #confusion_matrix(true, preds_select, labels=self.lables)\n","\n","        if verbose:\n","            print(\"\\nModel Results:\")\n","            print(\"Loss: %f\\nAccuracy: %f\\nPrecision: %f\\nRecall: %f\\nF1: %f\\nAUC: %f\\n\"%(loss, acc, pre, re, f1, auc))\n","            print(\"Classification Report:\")\n","            print(report)\n","            # print(\"\\nConfusion Matrix:\")\n","            # print(tabulate([[k] + list(cm[i]) for i, k in enumerate(list(self.labels_to_values_map.keys()))], \n","            #             [\"Activity\"] + list(label_map.keys()), \n","            #             tablefmt=\"grid\")\n","            # )\n","\n","        return loss, acc, pre, re, f1, auc, preds, report, cm"]},{"cell_type":"markdown","metadata":{"id":"jRumXrdownqz"},"source":["## Model Archetype Handler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K88kTgMiwp70"},"outputs":[],"source":["class ModelArchetypeHandler():\n","\n","    def __init__(self, archetype_name, experiment_name, source_labels, target_labels, save_dir=\"\", checkpoint_path=\"checkpoints/\", checkpoint_file_name=\"cp.ckpt\"):\n","        self.archetype_name = archetype_name\n","        self.experiment_name = experiment_name\n","        self.source_labels = source_labels\n","        self.target_labels = target_labels\n","        self.save_dir = save_dir\n","        self.checkpoint_path = save_dir + checkpoint_path\n","        self.checkpoint_file_name = checkpoint_file_name\n","        self.hist = {}\n","        self.tracker = None\n","        self.names = [\"naive\", \"initial_target\", \"transfer_target\", \"initial_comb\", \"transfer_comb\"]\n","\n","    # Build and Train Models ===================================================\n","    def run_experiment(self, input_shape_source, input_shape_target, train_layers, \n","                       data, x_key,\n","                       n_labels_source=6, n_labels_target=6, learning_rate=0.001, metrics=[\"accuracy\"], \n","                       epochs=10, n_runs=5, \n","                       verbose=True\n","                       ):\n","        \n","        tracker = []\n","        for run in range(n_runs):\n","            for n in self.names:\n","                if n not in self.hist:\n","                    self.hist.update({n: {}})\n","                if run not in self.hist[n]:\n","                    self.hist[n].update({run: None})\n","\n","            # Naive model\n","            level = \"naive\"\n","            header = \"\\n\\nRun %d, %s, %s ====\"%(run, self.archetype_name, level)\n","            print(header.ljust(85, \"=\"))\n","            self.n_model = ModelHandler(name=\"%s_%s_%d\"%(self.archetype_name, level, run), \n","                                        source_labels=self.source_labels, \n","                                        target_labels=self.target_labels, \n","                                        checkpoint_path=\"%s%s/%s/%d/\"%(self.checkpoint_path, self.archetype_name, level, run), \n","                                        checkpoint_file_name=self.checkpoint_file_name\n","                                        )\n","            self.n_model.build_model(self.archetype_name, input_shape_target, n_labels_target, learning_rate, metrics)\n","            self.n_model.train_model(level, \n","                                     data[\"target\"][\"train\"][x_key], data[\"target\"][\"train\"][\"y\"], \n","                                     data[\"target\"][\"val\"][x_key], data[\"target\"][\"val\"][\"y\"], \n","                                     epochs*2\n","                                     )\n","            self.hist[level][run] = self.n_model.hist[level]\n","            for test in [\"target\"]:\n","                loss, acc, pre, re, f1, auc, preds, report, cm = self.n_model.evaluate(data[test][\"test\"][x_key], \n","                                                                                       data[test][\"test\"][\"y\"], \n","                                                                                       verbose=verbose\n","                                                                                       )\n","                tracker.append([self.archetype_name, level, run, test, loss, acc, pre, re, f1, auc, report, cm, preds, self.n_model.hist[level]])\n","\n","            # Initial target model\n","            level = \"initial_target\"\n","            header = \"\\n\\nRun %d, %s, %s ====\"%(run, self.archetype_name, level)\n","            print(header.ljust(85, \"=\"))\n","            self.t_target_model = ModelHandler(name=\"%s_%s_%d\"%(self.archetype_name, level, run),\n","                                               source_labels=self.source_labels, \n","                                               target_labels=self.target_labels, \n","                                               checkpoint_path=\"%s%s/%s/%d/\"%(self.checkpoint_path, self.archetype_name, level, run), \n","                                               checkpoint_file_name=self.checkpoint_file_name\n","                                               )\n","            self.t_target_model.build_model(self.archetype_name, input_shape_source, n_labels_source, learning_rate, metrics)\n","            self.t_target_model.train_model(level, \n","                                            data[\"source\"][\"train\"][x_key], data[\"source\"][\"train\"][\"y\"], \n","                                            data[\"source\"][\"val\"][x_key], data[\"source\"][\"val\"][\"y\"], \n","                                            epochs\n","                                            )\n","            self.hist[level][run] = self.t_target_model.hist[level]\n","            for test in [\"source\"]:\n","                loss, acc, pre, re, f1, auc, preds, report, cm = self.t_target_model.evaluate(data[test][\"test\"][x_key], \n","                                                                                              data[test][\"test\"][\"y\"], \n","                                                                                              verbose=verbose\n","                                                                                              )\n","                tracker.append([self.archetype_name, level, run, test, loss, acc, pre, re, f1, auc, report, cm, preds, self.t_target_model.hist[level]])\n","\n","            # Transfer target model\n","            level = \"transfer_target\"\n","            header = \"\\n\\nRun %d, %s, %s ====\"%(run, self.archetype_name, level)\n","            print(header.ljust(85, \"=\"))\n","            self.t_target_model.build_transfer_model(train_layers, input_shape_target, n_labels_target)\n","            self.t_target_model.train_model(level, \n","                                            data[\"target\"][\"train\"][x_key], data[\"target\"][\"train\"][\"y\"], \n","                                            data[\"target\"][\"val\"][x_key], data[\"target\"][\"val\"][\"y\"], \n","                                            epochs\n","                                            )\n","            self.hist[level][run] = self.t_target_model.hist[level]\n","            for test in [\"target\"]:\n","                loss, acc, pre, re, f1, auc, preds, report, cm = self.t_target_model.evaluate(data[test][\"test\"][x_key], \n","                                                                                              data[test][\"test\"][\"y\"], \n","                                                                                              verbose=verbose\n","                                                                                              )\n","                tracker.append([self.archetype_name, level, run, test, loss, acc, pre, re, f1, auc, report, cm, preds, self.t_target_model.hist[level]])\n","                \n","        # Get run averages -----------------------------------------------------\n","\n","        # Set up averages collecter\n","        averages = {}\n","        for level in list(self.names):\n","            averages.update({level: {}})\n","            for test in [\"source\", \"target\"]:\n","                averages[level].update({test: [0, 0, 0, 0, 0, 0]})\n","        \n","        # Get scores\n","        for row in tracker:\n","            for i in range(4, 10):\n","                averages[row[1]][row[3]][i-4] += row[i]\n","        \n","        # Add average scores to tracker\n","        for level in list(self.names):\n","            for test in [\"source\", \"target\"]:\n","                avg = [self.archetype_name, level, -1, test, \n","                       averages[level][test][0]/n_runs, \n","                       averages[level][test][1]/n_runs, \n","                       averages[level][test][2]/n_runs, \n","                       averages[level][test][3]/n_runs, \n","                       averages[level][test][4]/n_runs, \n","                       averages[level][test][5]/n_runs, \n","                       np.nan, np.nan, np.nan, np.nan\n","                       ]\n","                tracker.append(avg)\n","\n","        # To dataframe\n","        self.tracker = sorted(tracker, key=lambda x: (x[0], x[1], x[2], x[3]))\n","        self.tracker = pd.DataFrame(self.tracker, columns=[\"model_archetype\", \"model_type\", \n","                                                 \"run\", \"test_level\", \"loss\", \n","                                                 \"accuracy\", \"precision\", \n","                                                 \"recall\", \"f1\", \"auc\", \"report\", \"confusion_matrix\", \n","                                                 \"predictions\", \"history\"\n","                                                 ])\n","        self.tracker[\"exp_name\"] = [self.experiment_name] * self.tracker.shape[0]\n","        self.tracker.to_csv(self.save_dir + \"trackers/\" + self.experiment_name + \"_\" + self.archetype_name + \".csv\", index=False)\n","\n","        with open(self.save_dir + \"histories/\" + self.experiment_name + \"_dense.pickle\", \"wb\") as file:\n","            pickle.dump(self.hist, file)\n","        \n","        return self.tracker"]},{"cell_type":"markdown","metadata":{"id":"lhd3tY-kwqNo"},"source":["## Dual Model Archetype Handler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZr-dxmMwteT"},"outputs":[],"source":["class DualModelArchetypeHandler():\n","\n","    def __init__(self, experiment_name, source_labels, target_labels, save_dir=\"\", checkpoint_path=\"checkpoints/\", checkpoint_file_name=\"cp.ckpt\"):\n","        self.experiment_name = experiment_name\n","        self.save_dir = save_dir\n","        self.checkpoint_path = checkpoint_path\n","        self.checkpoint_file_name = checkpoint_file_name\n","\n","        self.dense_handler = ModelArchetypeHandler(\"dense\", self.experiment_name, source_labels, target_labels, self.save_dir, self.checkpoint_path, self.checkpoint_file_name)\n","        self.conv_handler = ModelArchetypeHandler(\"conv\", self.experiment_name, source_labels, target_labels, self.save_dir, self.checkpoint_path, self.checkpoint_file_name)\n","        \n","    def run_experiment(self, dense_input_shape_source, dense_input_shape_target, \n","                       conv_input_shape_source, conv_input_shape_target, \n","                       dense_train_layers, conv_train_layers, \n","                       data, n_labels_source=6, n_labels_target=6, learning_rate=0.001, metrics=[\"accuracy\"], \n","                       epochs=10, n_runs=5, \n","                       verbose=True\n","                       ):\n","        \n","        self.dense_handler.run_experiment(input_shape_source=dense_input_shape_source, \n","                                          input_shape_target=dense_input_shape_target,\n","                                          train_layers=dense_train_layers, \n","                                          data=data, x_key=\"x\",\n","                                          n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                          learning_rate=learning_rate, metrics=metrics, \n","                                          epochs=epochs, n_runs=n_runs, \n","                                          verbose=verbose\n","                                          )\n","        \n","        self.conv_handler.run_experiment(input_shape_source=conv_input_shape_source, \n","                                         input_shape_target=conv_input_shape_target, \n","                                         train_layers=conv_train_layers, \n","                                         data=data, x_key=\"x_shaped\",\n","                                         n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                         learning_rate=learning_rate, metrics=metrics, \n","                                         epochs=epochs, n_runs=n_runs, \n","                                         verbose=verbose\n","                                         )\n","        \n","        self.dual_tracker = pd.concat([self.dense_handler.tracker, self.conv_handler.tracker])\n","        self.dual_tracker.to_csv(self.save_dir + \"trackers/\" + self.experiment_name + \"_dual\" + \".csv\", index=False)\n","        \n","        with open(self.save_dir + \"histories/\" + exp_name + \"_dense.pickle\", \"wb\") as file:\n","            pickle.dump(self.dense_handler.hist, file)\n","        with open(self.save_dir + \"histories/\" + exp_name + \"_conv.pickle\", \"wb\") as file:\n","            pickle.dump(self.conv_handler.hist, file)\n","\n","        return self.dual_tracker"]},{"cell_type":"markdown","metadata":{"id":"ajE5wcSG56gg"},"source":["# Plotting"]},{"cell_type":"markdown","metadata":{"id":"w4fcpAQflTNB"},"source":["## History"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pe9Vs5tl59nm"},"outputs":[],"source":["def plot_histories(dual_handler, n_runs, epochs, save=False, save_dir=\"\", save_name=\"\"):\n","    fig, ax = plt.subplots(4, 4, figsize=(15, 15))\n","    # col 0: accuracy\n","    # col 1: val accuracy\n","    # col 2: loss\n","    # col 3: val loss\n","    # row 0: dense naive\n","    # row 1: dense transfer target val\n","    # row 2: conv naive\n","    # row 3: conv transfer target val\n","\n","    # Subplot labels ===========================================================\n","    for i, architecture in enumerate([\"Dense\", \"Conv.\"]):\n","        for k, model in enumerate([\"Naive\", \"Transfer Target\"]): #, \"Transfer Combined\"]):\n","            for j, metric in enumerate([\"Accuracy\", \"Val. Accuracy\", \"Loss\", \"Val. Loss\"]):\n","                row = k\n","                # if i > 0:\n","                #     row += 2\n","                ax[row][j].set_xlabel(\"Epochs\")\n","                ax[row][j].set_ylabel(metric)\n","                ax[row][j].set_title(\" \".join([architecture, model, metric]))\n","\n","    # Subplots =================================================================\n","    labels = []\n","    avgs = {\"accuracy\": None, \n","            \"val_accuracy\": None, \n","            \"loss\": None, \n","            \"val_loss\": None\n","            }\n","    for run in range(n_runs):\n","        labels.append(\"Run %d\"%(run + 1))\n","        for j, score in enumerate([\"accuracy\", \"val_accuracy\", \"loss\", \"val_loss\"]):\n","\n","            # Dense\n","            ax[0][j].plot(dual_handler.dense_handler.hist[\"naive\"][run].history[score])\n","            ax[1][j].plot(dual_handler.dense_handler.hist[\"initial_target\"][run].history[score] + dual_handler.dense_handler.hist[\"transfer_target\"][run].history[score])\n","            # ax[2][j].plot(dual_handler.dense_handler.hist[\"initial_comb\"][run].history[score] + dual_handler.dense_handler.hist[\"transfer_comb\"][run].history[score])\n","\n","            # Conv\n","            ax[2][j].plot(dual_handler.conv_handler.hist[\"naive\"][run].history[score])\n","            ax[3][j].plot(dual_handler.conv_handler.hist[\"initial_target\"][run].history[score] + dual_handler.conv_handler.hist[\"transfer_target\"][run].history[score])\n","            # ax[5][j].plot(dual_handler.conv_handler.hist[\"initial_comb\"][run].history[score] + dual_handler.conv_handler.hist[\"transfer_comb\"][run].history[score])\n","\n","    # Plot limits ==============================================================\n","\n","    # Get values ---------------------------------------------------------------\n","    loss = [None, None]\n","    for i in range(4):\n","        for j in range(2):\n","\n","            # Loss min\n","            if loss[0] is None:\n","                loss[0] = ax[i][j+2].get_ylim()[0]\n","            elif loss[0] > ax[i][j+2].get_ylim()[0]:\n","                loss[0] = ax[i][j+2].get_ylim()[0]\n","\n","            # Loss max\n","            if loss[1] is None:\n","                loss[1] = ax[i][j+2].get_ylim()[1]\n","            elif loss[1] < ax[i][j+2].get_ylim()[1]:\n","                loss[1] = ax[i][j+2].get_ylim()[1]\n","                \n","    # Set values ---------------------------------------------------------------\n","    for i in range(4):\n","        for j in range(2):\n","            ax[i][j].set_ylim((0, 1))\n","            ax[i][j+2].set_ylim(loss)\n","    plt.setp(ax, xlim=(0, epochs*2-1))\n","\n","    # Plot =====================================================================\n","    fig.legend(labels=labels, loc=\"upper right\")\n","    plt.tight_layout()\n","    plt.subplots_adjust(right=0.9)\n","    if save:\n","        plt.savefig(save_dir + save_name)\n","    plt.plot()"]},{"cell_type":"markdown","metadata":{"id":"44Z9yhCku4aZ"},"source":["## Tracker Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvxcrPC6u8UC"},"outputs":[],"source":["def plot_scores(tracker, save=False, save_dir=\"\", save_name=\"\"):\n","    fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n","\n","    metrics = [[\"precision\", \"recall\"], [\"accuracy\", \"f1\"]]\n","    types = [\"naive\", \"initial_target\", \"transfer_target\"] #, \"initial_comb\", \"transfer_comb\"]\n","    test_sets = [\"target\"]\n","    archs = [\"dense\", \"conv\"]\n","    colors = [[\"xkcd:light orange\", \"xkcd:orange\"], [\"xkcd:sky blue\", \"xkcd:deep sky blue\"]]\n","    label_keys = []\n","\n","    for a in archs:\n","        for t in test_sets:\n","            label_keys.append(a + \" \" + t)\n","\n","    # Get scores\n","    for i in range(2):\n","        for j in range(2):\n","            m = metrics[i][j]\n","            df = tracker.loc[tracker[\"run\"] == -1]\n","\n","            w = 0.2\n","            x_ticks = {0: np.arange(len(types))}\n","            c = 0\n","            for k, a in enumerate(archs):\n","                for l, t in enumerate(test_sets):\n","                    tmp = df.loc[(df[\"test_level\"] == t) & (df[\"model_archetype\"] == a)]\n","                    vals = tmp[m].tolist()\n","                    print(vals)\n","                    vals = [vals[2], vals[1], vals[4], vals[0], vals[3]]\n","                    print(1)\n","                    idx = label_keys.index(\"%s %s\"%(a, t))\n","                    print(2)\n","                    ax[i][j].bar(x_ticks[c], vals, width=w) #, color=colors[k][l], label=label_keys[idx])\n","                    print(3)\n","                    c += 1\n","                    x_ticks.update({c: [x + w for x in x_ticks[c-1]]})\n","\n","            print(4)\n","            ax[i][j].set_xlabel(\"Model Type\")\n","            print(5)\n","            ax[i][j].set_ylabel(\"Score\")\n","            print(6)\n","            ax[i][j].set_title(m.capitalize())\n","            print(7)\n","\n","    plt.setp(ax, xticks=[x + w for x in range(len(types))], xticklabels=types)\n","    print(8)\n","    plt.tight_layout()\n","    print(9)\n","    plt.subplots_adjust(right=0.9)\n","    print(10)\n","    fig.legend(labels=label_keys, loc=\"upper right\")\n","    print(11)\n","    if save:\n","        plt.savefig(save_dir + save_name)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jyEu4HOTwvu2"},"source":["# Global Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zId8RoQxw4Eg"},"outputs":[],"source":["# File Handling\n","save_dir = \"/content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/\"      # Mica dir\n","checkpoint_path = \"checkpoints/exp_\"\n","cp_file = \"checkpoint.ckpt\"\n","hist_plot_dir = save_dir + \"hist_plots/\"\n","tracker_bar_dir = save_dir + \"tracker_bar_plots/\"\n","\n","# Image shapes\n","img_rows_source = 33\n","img_rows_target = 27\n","img_cols_source = 17\n","img_cols_target = 15\n","\n","# Model hyperparmeters\n","source_labels = sorted(list(source_labels))\n","target_labels = sorted(list(target_labels))\n","n_labels_source = len(source_labels) + 1\n","n_labels_target = len(target_labels) + 1\n","input_shape_dense_source = (561, )\n","input_shape_dense_target = (405, )\n","input_shape_conv_source = (img_rows_source, img_cols_source, 1)\n","input_shape_conv_target = (img_rows_target, img_cols_target, 1)\n","epochs = 20\n","n_runs = 5\n","\n","# History\n","tracker_global = {}"]},{"cell_type":"markdown","metadata":{"id":"lhHhGnbMvpEV"},"source":["# Experiments - Hyperparameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"m5TYSvczfEaL"},"source":["## Experiment 1 - Baseline"]},{"cell_type":"markdown","metadata":{"id":"EXl6wC6I8nlB"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqj9ydsJ8nWa"},"outputs":[],"source":["exp_name = \"001_baseline\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 1"]},{"cell_type":"markdown","metadata":{"id":"pfQTkNT2x8Fy"},"source":["### Run Experiment"]},{"cell_type":"code","source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tp2-nhUK2ugE","executionInfo":{"status":"error","timestamp":1668458724673,"user_tz":360,"elapsed":516544,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}},"outputId":"60159ef1-d716-4bfd-d7aa-e23237c203f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Run 0, dense, naive ===============================================================\n","Epoch 1/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.8113 - accuracy: 0.7287\n","Epoch 1: val_loss improved from inf to 0.55178, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/0/checkpoint.ckpt\n","120/120 [==============================] - 3s 19ms/step - loss: 0.8105 - accuracy: 0.7287 - val_loss: 0.5518 - val_accuracy: 0.7966\n","Epoch 2/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.4095 - accuracy: 0.8443\n","Epoch 2: val_loss improved from 0.55178 to 0.29735, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 17ms/step - loss: 0.4105 - accuracy: 0.8447 - val_loss: 0.2974 - val_accuracy: 0.8805\n","Epoch 3/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.8897\n","Epoch 3: val_loss improved from 0.29735 to 0.23504, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 17ms/step - loss: 0.3049 - accuracy: 0.8900 - val_loss: 0.2350 - val_accuracy: 0.9287\n","Epoch 4/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9175\n","Epoch 4: val_loss did not improve from 0.23504\n","120/120 [==============================] - 2s 16ms/step - loss: 0.2545 - accuracy: 0.9175 - val_loss: 0.3076 - val_accuracy: 0.8889\n","Epoch 5/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9293\n","Epoch 5: val_loss improved from 0.23504 to 0.19055, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 17ms/step - loss: 0.2178 - accuracy: 0.9293 - val_loss: 0.1905 - val_accuracy: 0.9350\n","Epoch 6/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.9444\n","Epoch 6: val_loss improved from 0.19055 to 0.18704, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 18ms/step - loss: 0.1793 - accuracy: 0.9440 - val_loss: 0.1870 - val_accuracy: 0.9329\n","Epoch 7/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9480\n","Epoch 7: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.1565 - accuracy: 0.9479 - val_loss: 0.2000 - val_accuracy: 0.9287\n","Epoch 8/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9475\n","Epoch 8: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.1635 - accuracy: 0.9476 - val_loss: 0.2377 - val_accuracy: 0.9203\n","Epoch 9/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9518\n","Epoch 9: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1419 - accuracy: 0.9518 - val_loss: 0.1877 - val_accuracy: 0.9413\n","Epoch 10/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9593\n","Epoch 10: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1239 - accuracy: 0.9594 - val_loss: 0.1900 - val_accuracy: 0.9392\n","Epoch 11/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9669\n","Epoch 11: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 0.1887 - val_accuracy: 0.9308\n","Epoch 12/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.9621\n","Epoch 12: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.1110 - accuracy: 0.9612 - val_loss: 0.2090 - val_accuracy: 0.9539\n","Epoch 13/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.9614\n","Epoch 13: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1125 - accuracy: 0.9612 - val_loss: 0.3421 - val_accuracy: 0.9057\n","Epoch 14/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9691\n","Epoch 14: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0945 - accuracy: 0.9691 - val_loss: 0.1889 - val_accuracy: 0.9392\n","Epoch 15/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9740\n","Epoch 15: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0764 - accuracy: 0.9736 - val_loss: 0.2441 - val_accuracy: 0.9350\n","Epoch 16/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9722\n","Epoch 16: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0836 - accuracy: 0.9722 - val_loss: 0.2343 - val_accuracy: 0.9371\n","Epoch 17/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9696\n","Epoch 17: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.1176 - accuracy: 0.9696 - val_loss: 0.2642 - val_accuracy: 0.9287\n","Epoch 18/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9751\n","Epoch 18: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0781 - accuracy: 0.9751 - val_loss: 0.2027 - val_accuracy: 0.9434\n","Epoch 19/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9804\n","Epoch 19: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0600 - accuracy: 0.9804 - val_loss: 0.2210 - val_accuracy: 0.9413\n","Epoch 20/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9897\n","Epoch 20: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.2176 - val_accuracy: 0.9434\n","Epoch 21/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9893\n","Epoch 21: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.2230 - val_accuracy: 0.9518\n","Epoch 22/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9840\n","Epoch 22: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 19ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.5058 - val_accuracy: 0.9015\n","Epoch 23/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9683\n","Epoch 23: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0942 - accuracy: 0.9683 - val_loss: 0.3346 - val_accuracy: 0.9224\n","Epoch 24/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9807\n","Epoch 24: val_loss did not improve from 0.18704\n","120/120 [==============================] - 3s 24ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.2965 - val_accuracy: 0.9350\n","Epoch 25/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9808\n","Epoch 25: val_loss did not improve from 0.18704\n","120/120 [==============================] - 3s 22ms/step - loss: 0.0660 - accuracy: 0.9806 - val_loss: 0.2193 - val_accuracy: 0.9371\n","Epoch 26/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9829\n","Epoch 26: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0512 - accuracy: 0.9830 - val_loss: 0.4140 - val_accuracy: 0.9203\n","Epoch 27/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9709\n","Epoch 27: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0946 - accuracy: 0.9709 - val_loss: 0.2597 - val_accuracy: 0.9434\n","Epoch 28/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9878\n","Epoch 28: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0301 - accuracy: 0.9880 - val_loss: 0.3134 - val_accuracy: 0.9476\n","Epoch 29/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9825\n","Epoch 29: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0467 - accuracy: 0.9825 - val_loss: 0.4200 - val_accuracy: 0.9287\n","Epoch 30/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9833\n","Epoch 30: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0556 - accuracy: 0.9835 - val_loss: 0.2241 - val_accuracy: 0.9413\n","Epoch 31/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9821\n","Epoch 31: val_loss did not improve from 0.18704\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0674 - accuracy: 0.9819 - val_loss: 0.2604 - val_accuracy: 0.9308\n","Epoch 32/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9805\n","Epoch 32: val_loss improved from 0.18704 to 0.16283, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0590 - accuracy: 0.9806 - val_loss: 0.1628 - val_accuracy: 0.9539\n","Epoch 33/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9845\n","Epoch 33: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.1797 - val_accuracy: 0.9455\n","Epoch 34/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9904\n","Epoch 34: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.3674 - val_accuracy: 0.9203\n","Epoch 35/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9882\n","Epoch 35: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.2732 - val_accuracy: 0.9434\n","Epoch 36/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9895\n","Epoch 36: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0284 - accuracy: 0.9895 - val_loss: 0.2926 - val_accuracy: 0.9476\n","Epoch 37/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9836\n","Epoch 37: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.3491 - val_accuracy: 0.9413\n","Epoch 38/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9846\n","Epoch 38: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 0.4036 - val_accuracy: 0.9308\n","Epoch 39/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9741\n","Epoch 39: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0858 - accuracy: 0.9738 - val_loss: 0.3000 - val_accuracy: 0.9392\n","Epoch 40/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9892\n","Epoch 40: val_loss did not improve from 0.16283\n","120/120 [==============================] - 2s 16ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.2833 - val_accuracy: 0.9308\n","15/15 [==============================] - 0s 6ms/step\n","15/15 - 0s - loss: 0.1654 - accuracy: 0.9456 - 81ms/epoch - 5ms/step\n","\n","\n","Run 0, dense, initial_target ======================================================\n","Epoch 1/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.8597\n","Epoch 1: val_loss improved from inf to 0.18815, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","515/515 [==============================] - 10s 19ms/step - loss: 0.3280 - accuracy: 0.8601 - val_loss: 0.1881 - val_accuracy: 0.9248\n","Epoch 2/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.1385 - accuracy: 0.9465\n","Epoch 2: val_loss did not improve from 0.18815\n","515/515 [==============================] - 9s 18ms/step - loss: 0.1388 - accuracy: 0.9464 - val_loss: 0.2482 - val_accuracy: 0.9039\n","Epoch 3/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9615\n","Epoch 3: val_loss improved from 0.18815 to 0.05390, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","515/515 [==============================] - 9s 18ms/step - loss: 0.1027 - accuracy: 0.9616 - val_loss: 0.0539 - val_accuracy: 0.9796\n","Epoch 4/20\n","512/515 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9651\n","Epoch 4: val_loss did not improve from 0.05390\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0934 - accuracy: 0.9650 - val_loss: 0.0587 - val_accuracy: 0.9767\n","Epoch 5/20\n","514/515 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9659\n","Epoch 5: val_loss did not improve from 0.05390\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0876 - accuracy: 0.9660 - val_loss: 0.0682 - val_accuracy: 0.9772\n","Epoch 6/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9702\n","Epoch 6: val_loss did not improve from 0.05390\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0801 - accuracy: 0.9701 - val_loss: 0.1265 - val_accuracy: 0.9451\n","Epoch 7/20\n","515/515 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9711\n","Epoch 7: val_loss improved from 0.05390 to 0.04796, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0769 - accuracy: 0.9711 - val_loss: 0.0480 - val_accuracy: 0.9820\n","Epoch 8/20\n","515/515 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9759\n","Epoch 8: val_loss did not improve from 0.04796\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0661 - accuracy: 0.9759 - val_loss: 0.0749 - val_accuracy: 0.9723\n","Epoch 9/20\n","515/515 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9749\n","Epoch 9: val_loss did not improve from 0.04796\n","515/515 [==============================] - 9s 17ms/step - loss: 0.0631 - accuracy: 0.9749 - val_loss: 0.1632 - val_accuracy: 0.9524\n","Epoch 10/20\n","514/515 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9787\n","Epoch 10: val_loss did not improve from 0.04796\n","515/515 [==============================] - 9s 17ms/step - loss: 0.0552 - accuracy: 0.9787 - val_loss: 0.0604 - val_accuracy: 0.9786\n","Epoch 11/20\n","514/515 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9750\n","Epoch 11: val_loss improved from 0.04796 to 0.04757, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0693 - accuracy: 0.9750 - val_loss: 0.0476 - val_accuracy: 0.9840\n","Epoch 12/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9761\n","Epoch 12: val_loss did not improve from 0.04757\n","515/515 [==============================] - 9s 17ms/step - loss: 0.0648 - accuracy: 0.9760 - val_loss: 0.0477 - val_accuracy: 0.9820\n","Epoch 13/20\n","515/515 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9758\n","Epoch 13: val_loss did not improve from 0.04757\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0584 - accuracy: 0.9758 - val_loss: 0.0526 - val_accuracy: 0.9806\n","Epoch 14/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9789\n","Epoch 14: val_loss did not improve from 0.04757\n","515/515 [==============================] - 9s 17ms/step - loss: 0.0525 - accuracy: 0.9789 - val_loss: 0.0796 - val_accuracy: 0.9733\n","Epoch 15/20\n","512/515 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9785\n","Epoch 15: val_loss did not improve from 0.04757\n","515/515 [==============================] - 11s 21ms/step - loss: 0.0595 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9757\n","Epoch 16/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9793\n","Epoch 16: val_loss did not improve from 0.04757\n","515/515 [==============================] - 9s 17ms/step - loss: 0.0528 - accuracy: 0.9793 - val_loss: 0.0768 - val_accuracy: 0.9762\n","Epoch 17/20\n","512/515 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9835\n","Epoch 17: val_loss improved from 0.04757 to 0.03464, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0407 - accuracy: 0.9835 - val_loss: 0.0346 - val_accuracy: 0.9859\n","Epoch 18/20\n","512/515 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9836\n","Epoch 18: val_loss did not improve from 0.03464\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0408 - accuracy: 0.9836 - val_loss: 0.0660 - val_accuracy: 0.9743\n","Epoch 19/20\n","512/515 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9799\n","Epoch 19: val_loss did not improve from 0.03464\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0584 - accuracy: 0.9799 - val_loss: 0.0534 - val_accuracy: 0.9714\n","Epoch 20/20\n","514/515 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9791\n","Epoch 20: val_loss did not improve from 0.03464\n","515/515 [==============================] - 9s 18ms/step - loss: 0.0572 - accuracy: 0.9791 - val_loss: 0.0421 - val_accuracy: 0.9816\n","65/65 [==============================] - 0s 6ms/step\n","65/65 - 0s - loss: 0.0502 - accuracy: 0.9825 - 313ms/epoch - 5ms/step\n","\n","\n","Run 0, dense, transfer_target =====================================================\n","Epoch 1/20\n","118/120 [============================>.] - ETA: 0s - loss: 0.8708 - accuracy: 0.0000e+00\n","Epoch 1: val_loss improved from inf to 0.53704, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 16ms/step - loss: 0.8704 - accuracy: 0.0000e+00 - val_loss: 0.5370 - val_accuracy: 0.0000e+00\n","Epoch 2/20\n","118/120 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.0000e+00\n","Epoch 2: val_loss improved from 0.53704 to 0.42909, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 15ms/step - loss: 0.5073 - accuracy: 0.0000e+00 - val_loss: 0.4291 - val_accuracy: 0.0000e+00\n","Epoch 3/20\n","116/120 [============================>.] - ETA: 0s - loss: 0.4066 - accuracy: 0.0000e+00\n","Epoch 3: val_loss improved from 0.42909 to 0.35920, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 14ms/step - loss: 0.4078 - accuracy: 0.0000e+00 - val_loss: 0.3592 - val_accuracy: 0.0000e+00\n","Epoch 4/20\n","117/120 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.0000e+00\n","Epoch 4: val_loss improved from 0.35920 to 0.29238, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 14ms/step - loss: 0.3189 - accuracy: 0.0000e+00 - val_loss: 0.2924 - val_accuracy: 0.0000e+00\n","Epoch 5/20\n","118/120 [============================>.] - ETA: 0s - loss: 0.2698 - accuracy: 0.0000e+00\n","Epoch 5: val_loss did not improve from 0.29238\n","120/120 [==============================] - 2s 13ms/step - loss: 0.2709 - accuracy: 0.0000e+00 - val_loss: 0.2940 - val_accuracy: 0.0000e+00\n","Epoch 6/20\n","116/120 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.0000e+00\n","Epoch 6: val_loss improved from 0.29238 to 0.28058, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 14ms/step - loss: 0.2281 - accuracy: 0.0000e+00 - val_loss: 0.2806 - val_accuracy: 0.0000e+00\n","Epoch 7/20\n","116/120 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.0000e+00\n","Epoch 7: val_loss improved from 0.28058 to 0.21952, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 15ms/step - loss: 0.2322 - accuracy: 0.0000e+00 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n","Epoch 8/20\n","117/120 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.0000e+00\n","Epoch 8: val_loss did not improve from 0.21952\n","120/120 [==============================] - 2s 14ms/step - loss: 0.2352 - accuracy: 0.0000e+00 - val_loss: 0.2420 - val_accuracy: 0.0000e+00\n","Epoch 9/20\n","118/120 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.0000e+00\n","Epoch 9: val_loss did not improve from 0.21952\n","120/120 [==============================] - 2s 13ms/step - loss: 0.2029 - accuracy: 0.0000e+00 - val_loss: 0.2494 - val_accuracy: 0.0000e+00\n","Epoch 10/20\n","119/120 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.0000e+00\n","Epoch 10: val_loss improved from 0.21952 to 0.21163, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 15ms/step - loss: 0.1841 - accuracy: 0.0000e+00 - val_loss: 0.2116 - val_accuracy: 0.0000e+00\n","Epoch 11/20\n","117/120 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.0000e+00\n","Epoch 11: val_loss did not improve from 0.21163\n","120/120 [==============================] - 2s 13ms/step - loss: 0.1541 - accuracy: 0.0000e+00 - val_loss: 0.2663 - val_accuracy: 0.0000e+00\n","Epoch 12/20\n","117/120 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.0000e+00\n","Epoch 12: val_loss did not improve from 0.21163\n","120/120 [==============================] - 2s 14ms/step - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.2736 - val_accuracy: 0.0000e+00\n","Epoch 13/20\n","119/120 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.0000e+00\n","Epoch 13: val_loss did not improve from 0.21163\n","120/120 [==============================] - 2s 13ms/step - loss: 0.1304 - accuracy: 0.0000e+00 - val_loss: 0.2795 - val_accuracy: 0.0000e+00\n","Epoch 14/20\n","116/120 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.0000e+00\n","Epoch 14: val_loss improved from 0.21163 to 0.18883, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/0/checkpoint.ckpt\n","120/120 [==============================] - 2s 14ms/step - loss: 0.1408 - accuracy: 0.0000e+00 - val_loss: 0.1888 - val_accuracy: 0.0000e+00\n","Epoch 15/20\n","117/120 [============================>.] - ETA: 0s - loss: 0.1535 - accuracy: 0.0000e+00\n","Epoch 15: val_loss did not improve from 0.18883\n","120/120 [==============================] - 2s 13ms/step - loss: 0.1516 - accuracy: 0.0000e+00 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n","Epoch 16/20\n","116/120 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.0000e+00\n","Epoch 16: val_loss did not improve from 0.18883\n","120/120 [==============================] - 2s 13ms/step - loss: 0.1325 - accuracy: 0.0000e+00 - val_loss: 0.3279 - val_accuracy: 0.0000e+00\n","Epoch 17/20\n","120/120 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.0000e+00\n","Epoch 17: val_loss did not improve from 0.18883\n","120/120 [==============================] - 2s 13ms/step - loss: 0.1046 - accuracy: 0.0000e+00 - val_loss: 0.2330 - val_accuracy: 0.0000e+00\n","Epoch 18/20\n","119/120 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.0000e+00\n","Epoch 18: val_loss did not improve from 0.18883\n","120/120 [==============================] - 2s 13ms/step - loss: 0.0965 - accuracy: 0.0000e+00 - val_loss: 0.2443 - val_accuracy: 0.0000e+00\n","Epoch 19/20\n","118/120 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.0000e+00\n","Epoch 19: val_loss did not improve from 0.18883\n","120/120 [==============================] - 2s 14ms/step - loss: 0.1105 - accuracy: 0.0000e+00 - val_loss: 0.2112 - val_accuracy: 0.0000e+00\n","Epoch 20/20\n","119/120 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.0000e+00\n","Epoch 20: val_loss did not improve from 0.18883\n","120/120 [==============================] - 2s 14ms/step - loss: 0.0847 - accuracy: 0.0000e+00 - val_loss: 0.2900 - val_accuracy: 0.0000e+00\n","15/15 [==============================] - 0s 5ms/step\n","15/15 - 0s - loss: 0.1891 - accuracy: 0.0000e+00 - 78ms/epoch - 5ms/step\n","\n","\n","Run 1, dense, naive ===============================================================\n","Epoch 1/40\n","118/120 [============================>.] - ETA: 0s - loss: 1.0563 - accuracy: 0.6377\n","Epoch 1: val_loss improved from inf to 0.58663, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/1/checkpoint.ckpt\n","120/120 [==============================] - 3s 19ms/step - loss: 1.0518 - accuracy: 0.6392 - val_loss: 0.5866 - val_accuracy: 0.7841\n","Epoch 2/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.8591\n","Epoch 2: val_loss improved from 0.58663 to 0.28098, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/1/checkpoint.ckpt\n","120/120 [==============================] - 2s 18ms/step - loss: 0.4063 - accuracy: 0.8594 - val_loss: 0.2810 - val_accuracy: 0.8994\n","Epoch 3/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.9023\n","Epoch 3: val_loss did not improve from 0.28098\n","120/120 [==============================] - 2s 17ms/step - loss: 0.2911 - accuracy: 0.9026 - val_loss: 0.5344 - val_accuracy: 0.8470\n","Epoch 4/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9186\n","Epoch 4: val_loss improved from 0.28098 to 0.19515, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/1/checkpoint.ckpt\n","120/120 [==============================] - 2s 18ms/step - loss: 0.2558 - accuracy: 0.9186 - val_loss: 0.1951 - val_accuracy: 0.9350\n","Epoch 5/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9364\n","Epoch 5: val_loss did not improve from 0.19515\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1915 - accuracy: 0.9364 - val_loss: 0.2160 - val_accuracy: 0.9392\n","Epoch 6/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9465\n","Epoch 6: val_loss improved from 0.19515 to 0.19426, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/1/checkpoint.ckpt\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1641 - accuracy: 0.9466 - val_loss: 0.1943 - val_accuracy: 0.9308\n","Epoch 7/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9387\n","Epoch 7: val_loss did not improve from 0.19426\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1828 - accuracy: 0.9387 - val_loss: 0.2193 - val_accuracy: 0.9497\n","Epoch 8/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9540\n","Epoch 8: val_loss improved from 0.19426 to 0.19359, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/1/checkpoint.ckpt\n","120/120 [==============================] - 2s 18ms/step - loss: 0.1463 - accuracy: 0.9537 - val_loss: 0.1936 - val_accuracy: 0.9413\n","Epoch 9/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9513\n","Epoch 9: val_loss did not improve from 0.19359\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1371 - accuracy: 0.9513 - val_loss: 0.2288 - val_accuracy: 0.9350\n","Epoch 10/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.9540\n","Epoch 10: val_loss did not improve from 0.19359\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1348 - accuracy: 0.9542 - val_loss: 0.1953 - val_accuracy: 0.9413\n","Epoch 11/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9567\n","Epoch 11: val_loss did not improve from 0.19359\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1267 - accuracy: 0.9565 - val_loss: 0.3366 - val_accuracy: 0.9161\n","Epoch 12/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9538\n","Epoch 12: val_loss did not improve from 0.19359\n","120/120 [==============================] - 2s 17ms/step - loss: 0.1227 - accuracy: 0.9529 - val_loss: 0.2331 - val_accuracy: 0.9371\n","Epoch 13/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9653\n","Epoch 13: val_loss improved from 0.19359 to 0.16407, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/naive/1/checkpoint.ckpt\n","120/120 [==============================] - 2s 18ms/step - loss: 0.1002 - accuracy: 0.9654 - val_loss: 0.1641 - val_accuracy: 0.9476\n","Epoch 14/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 0.9658\n","Epoch 14: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0923 - accuracy: 0.9657 - val_loss: 0.1986 - val_accuracy: 0.9413\n","Epoch 15/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9661\n","Epoch 15: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0936 - accuracy: 0.9665 - val_loss: 0.1817 - val_accuracy: 0.9518\n","Epoch 16/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9728\n","Epoch 16: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0699 - accuracy: 0.9733 - val_loss: 0.2330 - val_accuracy: 0.9350\n","Epoch 17/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9693\n","Epoch 17: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0936 - accuracy: 0.9699 - val_loss: 0.2647 - val_accuracy: 0.9434\n","Epoch 18/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9725\n","Epoch 18: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0799 - accuracy: 0.9725 - val_loss: 0.3189 - val_accuracy: 0.9078\n","Epoch 19/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9741\n","Epoch 19: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0688 - accuracy: 0.9738 - val_loss: 0.2418 - val_accuracy: 0.9434\n","Epoch 20/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9835\n","Epoch 20: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0490 - accuracy: 0.9835 - val_loss: 0.2777 - val_accuracy: 0.9350\n","Epoch 21/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9848\n","Epoch 21: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.2836 - val_accuracy: 0.9329\n","Epoch 22/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9720\n","Epoch 22: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0935 - accuracy: 0.9720 - val_loss: 0.1973 - val_accuracy: 0.9455\n","Epoch 23/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9845\n","Epoch 23: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.4263 - val_accuracy: 0.9078\n","Epoch 24/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9840\n","Epoch 24: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.5445 - val_accuracy: 0.9287\n","Epoch 25/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.9711\n","Epoch 25: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0937 - accuracy: 0.9715 - val_loss: 0.1854 - val_accuracy: 0.9560\n","Epoch 26/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 0.9801\n","Epoch 26: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0711 - accuracy: 0.9801 - val_loss: 0.2234 - val_accuracy: 0.9392\n","Epoch 27/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9821\n","Epoch 27: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0530 - accuracy: 0.9822 - val_loss: 0.2272 - val_accuracy: 0.9413\n","Epoch 28/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9869\n","Epoch 28: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 19ms/step - loss: 0.0358 - accuracy: 0.9869 - val_loss: 0.2092 - val_accuracy: 0.9518\n","Epoch 29/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9845\n","Epoch 29: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0534 - accuracy: 0.9848 - val_loss: 0.3221 - val_accuracy: 0.9329\n","Epoch 30/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9801\n","Epoch 30: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.3166 - val_accuracy: 0.9350\n","Epoch 31/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9947\n","Epoch 31: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.4459 - val_accuracy: 0.9413\n","Epoch 32/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9874\n","Epoch 32: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.2609 - val_accuracy: 0.9434\n","Epoch 33/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.9820\n","Epoch 33: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.1924 - val_accuracy: 0.9392\n","Epoch 34/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9913\n","Epoch 34: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0230 - accuracy: 0.9914 - val_loss: 0.1966 - val_accuracy: 0.9497\n","Epoch 35/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9942\n","Epoch 35: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.2361 - val_accuracy: 0.9392\n","Epoch 36/40\n","117/120 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9861\n","Epoch 36: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0536 - accuracy: 0.9856 - val_loss: 0.3477 - val_accuracy: 0.9371\n","Epoch 37/40\n","118/120 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9770\n","Epoch 37: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0843 - accuracy: 0.9770 - val_loss: 0.2251 - val_accuracy: 0.9434\n","Epoch 38/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9851\n","Epoch 38: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0382 - accuracy: 0.9851 - val_loss: 0.1825 - val_accuracy: 0.9539\n","Epoch 39/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9934\n","Epoch 39: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 18ms/step - loss: 0.0146 - accuracy: 0.9935 - val_loss: 0.2689 - val_accuracy: 0.9581\n","Epoch 40/40\n","119/120 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9937\n","Epoch 40: val_loss did not improve from 0.16407\n","120/120 [==============================] - 2s 17ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.2399 - val_accuracy: 0.9560\n","15/15 [==============================] - 0s 6ms/step\n","15/15 - 0s - loss: 0.1713 - accuracy: 0.9435 - 76ms/epoch - 5ms/step\n","\n","\n","Run 1, dense, initial_target ======================================================\n","Epoch 1/20\n","515/515 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.8721\n","Epoch 1: val_loss improved from inf to 0.19416, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/1/checkpoint.ckpt\n","515/515 [==============================] - 11s 19ms/step - loss: 0.3084 - accuracy: 0.8721 - val_loss: 0.1942 - val_accuracy: 0.9184\n","Epoch 2/20\n","515/515 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9474\n","Epoch 2: val_loss improved from 0.19416 to 0.09974, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/1/checkpoint.ckpt\n","515/515 [==============================] - 10s 19ms/step - loss: 0.1363 - accuracy: 0.9474 - val_loss: 0.0997 - val_accuracy: 0.9699\n","Epoch 3/20\n","513/515 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9626\n","Epoch 3: val_loss did not improve from 0.09974\n","515/515 [==============================] - 10s 19ms/step - loss: 0.1007 - accuracy: 0.9627 - val_loss: 0.2103 - val_accuracy: 0.9102\n","Epoch 4/20\n","514/515 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9681\n","Epoch 4: val_loss improved from 0.09974 to 0.06055, saving model to /content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/Group Project 2/Results/checkpoints/exp_001_baseline/dense/initial_target/1/checkpoint.ckpt\n","515/515 [==============================] - 10s 19ms/step - loss: 0.0842 - accuracy: 0.9681 - val_loss: 0.0606 - val_accuracy: 0.9772\n","Epoch 5/20\n","515/515 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9716\n","Epoch 5: val_loss did not improve from 0.06055\n","515/515 [==============================] - 11s 22ms/step - loss: 0.0743 - accuracy: 0.9716 - val_loss: 0.0699 - val_accuracy: 0.9714\n","Epoch 6/20\n","515/515 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9739\n","Epoch 6: val_loss did not improve from 0.06055\n","515/515 [==============================] - 10s 19ms/step - loss: 0.0715 - accuracy: 0.9739 - val_loss: 0.0919 - val_accuracy: 0.9646\n","Epoch 7/20\n","163/515 [========>.....................] - ETA: 6s - loss: 0.0618 - accuracy: 0.9776"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-3d83d28b7ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                             )\n","\u001b[0;32m<ipython-input-37-c7dfe15dcf0d>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, input_shape_source, input_shape_target, train_layers, data, x_key, n_labels_source, n_labels_target, learning_rate, metrics, epochs, n_runs, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                             \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                                             )\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_target_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-36-1a523b46a182>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, experiment_level, train_x, train_y, val_x, val_y, epochs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                                                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                                                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                                                      \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcp_callbacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment_level\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                                                      )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["t"],"metadata":{"id":"PLCaaQceAJE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vc4ED3abvRcz"},"source":["## Experiment 2 - Drop Learning Rate 1"]},{"cell_type":"markdown","metadata":{"id":"cROMvEruwJsF"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbrmKC17yiF7"},"outputs":[],"source":["exp_name = \"002_drop_learning_rate_1\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.0001\n","dense_train_layers = 1"]},{"cell_type":"markdown","metadata":{"id":"S1NpBb7Dyllf"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kiOVpO0ayn9I"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )"]},{"cell_type":"code","source":["t"],"metadata":{"id":"Zn3BcR-FBMtb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZUR79kfkE4p"},"source":["## Experiment 3 - Drop Learning Rate 2"]},{"cell_type":"markdown","metadata":{"id":"5EGh1bcxJTHV"},"source":["### Hyperparameters"]},{"cell_type":"code","source":["exp_name = \"003_drop_learning_rate_2\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.00001\n","dense_train_layers = 1"],"metadata":{"id":"6YCrd7-IJyOA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFagcdxgyyYs"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDnhsHrHyzwm"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )"]},{"cell_type":"code","source":["t"],"metadata":{"id":"MGcTLUEbJ5qX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTAuY7qT7zBz"},"source":["## Experiment 4 - Raise Learning Rate 1"]},{"cell_type":"markdown","metadata":{"id":"292yj8k173ZW"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ayYzxd5Eyg5p"},"outputs":[],"source":["exp_name = \"004_raise_learning_rate_1\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.01\n","dense_train_layers = 1"]},{"cell_type":"markdown","metadata":{"id":"5IjYVEYpy06B"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9tccbg_Xy2X7"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )"]},{"cell_type":"code","source":["t"],"metadata":{"id":"joPoW-DxJ8rN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7le3xc0-wknJ"},"source":["## Experiment 5 - Raise Number of Unforzen Layers by 1"]},{"cell_type":"markdown","metadata":{"id":"wAy11KCMwpDB"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6fTwU4AMwqvh"},"outputs":[],"source":["exp_name = \"005_raise_num_unfrozen_1\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 2"]},{"cell_type":"markdown","metadata":{"id":"vU4a3F2vwrBE"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGgUxBFIwtGB"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","metadata":{"id":"9OJuUQyMs0nO"},"source":["## Experiment 6 - Raise Number of Unforzen Layers by 2"]},{"cell_type":"markdown","metadata":{"id":"fupN4vsGtjyo"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GruNZ0kAtlbY"},"outputs":[],"source":["exp_name = \"006_raise_num_unfrozen_2\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 3"]},{"cell_type":"markdown","metadata":{"id":"23RSpRn3trU4"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xga_KBUNtxqY"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","metadata":{"id":"zSMCHL1Ts5JL"},"source":["## Experiment 7 - Raise Number of Unforzen Layers by 3"]},{"cell_type":"markdown","metadata":{"id":"ThI7B8PJtdHb"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaTdrR-ntezT"},"outputs":[],"source":["exp_name = \"007_raise_num_unfrozen_3\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 4"]},{"cell_type":"markdown","metadata":{"id":"-_rZm-A6tggr"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNX3p7hAtioT"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","metadata":{"id":"2SHmtI8ns83q"},"source":["## Experiment 8 - Raise Number of Unforzen Layers by 4\n"]},{"cell_type":"markdown","metadata":{"id":"1EzF2HpbtQ4p"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3EqrY4gtS1p"},"outputs":[],"source":["exp_name = \"008_raise_num_unfrozen_4\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 5"]},{"cell_type":"markdown","metadata":{"id":"jA4ZRU77tVPL"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoQENEirtXcr"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","metadata":{"id":"WCBj6ExL7z_z"},"source":["## Experiment 9 - Raise Number of Unforzen Layers by 5"]},{"cell_type":"markdown","metadata":{"id":"Ey0AID9i76Ab"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MH89mv1K8AJV"},"outputs":[],"source":["exp_name = \"009_raise_num_unfrozen_5\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 6"]},{"cell_type":"markdown","metadata":{"id":"PCAnQIc978L7"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUSElWKc79pc"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","metadata":{"id":"hqx2QW8q8N07"},"source":["## Experiment 10 - Raise Number of Unforzen Layers by 6"]},{"cell_type":"markdown","metadata":{"id":"30w01KWj8Wx7"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xbBgWSvm8Wh0"},"outputs":[],"source":["exp_name = \"010_raise_num_unfrozen_6\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 7"]},{"cell_type":"markdown","metadata":{"id":"AGVWV7D58ZH5"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8HcFxT88aeJ"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","metadata":{"id":"FLau4Hz18a90"},"source":["## Experiment 11 - Raise Number of Unforzen Layers by 7"]},{"cell_type":"markdown","metadata":{"id":"EA2tqhyU82Xp"},"source":["### Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq6XY1Ke82IT"},"outputs":[],"source":["exp_name = \"011_raise_num_unfrozen_7\"\n","\n","# File handling\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 8"]},{"cell_type":"markdown","metadata":{"id":"PIbMNDIp84eb"},"source":["### Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQ6I4mgx86QZ"},"outputs":[],"source":["single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                         checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                         )\n","t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                            dense_train_layers, \n","                            data=data, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                            learning_rate=learning_rate, \n","                            epochs=epochs, n_runs=n_runs, \n","                            verbose=False\n","                            )\n","t"]},{"cell_type":"markdown","source":["# Experiments - Scores vs Data"],"metadata":{"id":"EEnVIBnzyU1L"}},{"cell_type":"markdown","source":["Hyperparameters:\n","* Learning Rate: 0.001\n","* train_layers = 6"],"metadata":{"id":"zPs38Bm7rIOQ"}},{"cell_type":"markdown","source":["## Base Hyperparameters"],"metadata":{"id":"6gQn09XpIk5n"}},{"cell_type":"code","source":["exp_name_base = \"_data_vs_score_keep_\"\n","c = 11\n","\n","# File handling\n","# exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","\n","# Data\n","keep = 0\n","\n","# Training\n","learning_rate = 0.001\n","dense_train_layers = 6"],"metadata":{"id":"5cKDkwuQr0EO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Select Data Function"],"metadata":{"id":"sNFqgHrAIo2Z"}},{"cell_type":"code","source":["def select_data(data, keep):\n","    data_new = {\"source\": deepcopy(data[\"source\"]), \"target\": {}}\n","    c = {}\n","    drops = []\n","    for i in range(1, 7):\n","        c.update({i: 0})\n","\n","    for i, row in data[\"target\"][\"train\"][\"y\"].iterrows():\n","        x = row[\"label\"]\n","\n","        if c[x] == keep:\n","            drops.append(i)\n","        else:\n","            c[x] += 1\n","\n","    for k in [\"val\", \"test\"]:\n","        data_new[\"target\"].update({k: deepcopy(data[\"target\"][k])})\n","\n","    data_new[\"target\"].update({\"train\": {}})\n","    for k in [\"x\", \"y\"]:\n","        data_new[\"target\"][\"train\"].update({k: data[\"target\"][\"train\"][k].drop(drops)})\n","\n","    return data_new"],"metadata":{"id":"Y6xLJW89tjqH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get Max Keep Count"],"metadata":{"id":"B-15FPcEIrwE"}},{"cell_type":"code","source":["low = 100000\n","for i in range(1, 7):\n","    tmp = data[\"target\"][\"train\"][\"y\"].loc[data[\"target\"][\"train\"][\"y\"][\"label\"] == i]\n","    if tmp.size < low:\n","        low = tmp.size\n","    print(i, tmp.size, low)"],"metadata":{"id":"Ap7Zdr00FE9D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experiments"],"metadata":{"id":"ATR4tfybIwVm"}},{"cell_type":"markdown","source":["### Experiment 12 - Keep 5"],"metadata":{"id":"98b67fFbIyG_"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 12\n","keep = 5\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"WbQfJ-nmGdO3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 13 - Keep 10"],"metadata":{"id":"PRHh91DZI7HA"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 13\n","keep= 10\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"VEOw430pH7oV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 14 - Keep 15"],"metadata":{"id":"n0ytCxRGI-E5"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 14\n","keep = 15\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"BaX72lHIH-5s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 15 - Keep 20"],"metadata":{"id":"z7jWwiZsJCPt"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 15\n","keep = 20\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"9R0_6SrVH_-a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 16 - Keep 25"],"metadata":{"id":"5NOA9X3yJGvI"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 16\n","keep = 25\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"rWuP7buKICP_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 17 - Keep 30"],"metadata":{"id":"RHo3AHbYJJWT"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 17\n","keep = 30\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"WkZnI9bQIDJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 18 - Keep 35"],"metadata":{"id":"9F6GgewmJMtH"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 18\n","keep = 35\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"9meB-TLKID9T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 19 - Keep 40"],"metadata":{"id":"DbGliMWLJPLt"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 19\n","keep = 40\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"9ROTGYgxIEri"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 20 - Keep 45"],"metadata":{"id":"dE9LLEIAJRy2"}},{"cell_type":"code","source":[" with open(save_dir + \"histories/\" + single_handler.experiment_name + \"_dense.pickle\", \"wb\") as file:\n","    pickle.dump(single_handler.hist, file)"],"metadata":{"id":"1zGhcdJE9-IC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","c = 20\n","keep = 45\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"cOBxwLPPIFbh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 21 - Keep 50"],"metadata":{"id":"Q31RtXklJWOr"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 21\n","keep = 50\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"Um-KAXgQIGaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 22 - Keep 55"],"metadata":{"id":"E9I9Fw4dJYlg"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 22\n","keep = 55\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"JMbLnWq6IHLA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 23 - Keep 60"],"metadata":{"id":"ah2F_YHoJbuD"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 23\n","keep = 60\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"3WSAj5F_IH_L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 24 - Keep 65"],"metadata":{"id":"N5-45s8RJeUg"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 24\n","keep = 65\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"eRyN-wc3IJCL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 25 - Keep 70"],"metadata":{"id":"eFn6DeDgJg-f"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 25\n","keep = 70\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"98-4ZhzzIJ5s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 26 - Keep 75"],"metadata":{"id":"3unHCB8mJj5j"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 26\n","keep= 75\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"5uY2Vco0IKwu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 27 - Keep 80"],"metadata":{"id":"3c_5FyJbJm8I"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 27\n","keep = 80\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"GPYNwfnfILmO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 28 - Keep 85"],"metadata":{"id":"sB-qAhYHJpIF"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 28\n","keep = 85\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"ValmblBQIMW5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 29 - Keep 90"],"metadata":{"id":"_VsofN2aJryQ"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 29\n","keep = 90\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"IWbo4yBhINKA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 30 - Keep 95"],"metadata":{"id":"5ONQ04BMJvAQ"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 30\n","keep = 95\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"3wUxQRGKIN8-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 31 - Keep 100"],"metadata":{"id":"5pD2NfkXJy0f"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 31\n","keep = 100\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"AnCF69Y3IOsb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 32 - Keep 105"],"metadata":{"id":"859NDZbbJ1sc"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 32\n","keep = 105\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"T_18QZ3vIPgK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 33 - Keep 110"],"metadata":{"id":"rW7XSee_J3z-"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 33\n","keep = 110\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"-CbBXa_OIQY6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 34 - Keep 115"],"metadata":{"id":"-jisMbMaJ6tQ"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 34\n","keep = 115\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"mkIXbgROIUoT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 35 - Keep 120"],"metadata":{"id":"UAPLB8daJ9WV"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 35\n","keep = 120\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"qzPmnf6uIWBG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 36 - Keep 125"],"metadata":{"id":"gwSVXP5KKABk"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 36\n","keep = 125\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"3BYUwHkWIXOp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 37 - Keep 130"],"metadata":{"id":"WOxEnVG3KCYm"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 37\n","keep = 130\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"x4AyjN5bIX-0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 38 - Keep 135"],"metadata":{"id":"nDfPCbbSKFV6"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 38\n","keep = 135\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"z0HrOfFEIZEX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 39 - Keep 140"],"metadata":{"id":"zKDwVhANKHiJ"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 39\n","keep = 140\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"-NgLkfdaIZzt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 40 - Keep 145"],"metadata":{"id":"tJCfRdJ4KKT5"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 40\n","keep = 145\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"7wjN0e8eIamR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 41 - Keep 150"],"metadata":{"id":"-ylD-IUGKOX2"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 41\n","keep = 150\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"Uq4DM2K6IbUr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 42 - Keep 155"],"metadata":{"id":"5rYj9OmgKQn_"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 42\n","keep = 155\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"mZN0njTHIcFN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Experiment 43 - Keep 160"],"metadata":{"id":"WWp0nrIwKTB-"}},{"cell_type":"code","source":["# Hyperparameters\n","c = 43\n","keep = 160\n","exp_name = str(c) + exp_name_base + str(keep)\n","exp_checkpoint_path = checkpoint_path + exp_name + \"/\"\n","print(exp_name)\n","\n","# Data\n","if low >= keep:\n","    data_new = select_data(data, keep)\n","\n","    # Train\n","    single_handler = ModelArchetypeHandler(\"dense\", exp_name, source_labels, target_labels, save_dir=save_dir, \n","                                            checkpoint_path=exp_checkpoint_path, checkpoint_file_name=cp_file\n","                                            )\n","    t = single_handler.run_experiment(input_shape_dense_source, input_shape_dense_target, \n","                                dense_train_layers, \n","                                data=data_new, x_key=\"x\", n_labels_source=n_labels_source, n_labels_target=n_labels_target, \n","                                learning_rate=learning_rate, \n","                                epochs=epochs, n_runs=n_runs, \n","                                verbose=False\n","                                )\n","    t"],"metadata":{"id":"1Yw4PSqVIc7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://stackoverflow.com/questions/73029592/transfer-learning-from-a-custom-model-trained-with-different-image-sizes"],"metadata":{"id":"HpznLqEHzCHq"}},{"cell_type":"markdown","metadata":{"id":"pY9iuOriQZFp"},"source":["# Bottom"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}