{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"C-UDryYDp14y"},"outputs":[],"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Activation\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","import pandas as pd\n","import numpy as np\n","from keras.models import load_model\n","import os\n","import time\n","from datetime import datetime\n","# CSV learning rate\n","from keras.callbacks import CSVLogger\n","\n","# history\n","from keras.callbacks import History"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obWZ2MX5rG3A"},"outputs":[],"source":["# To download dataset from google drive\n","!pip install gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoK5D7dFrF_y"},"outputs":[],"source":["!gdown --folder https://drive.google.com/drive/folders/1K1Fg2AzMKnjcaMDHjvuhe0hs9tdpb3ZU?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ooXjC6XKp9wE"},"outputs":[],"source":["#Specify the number of features. w-HAR:120, UCI-HAR/UCI-HAPT:561, unimib:453, WISDM:405\n","featurenums = 405\n","#Specify the shape of 2D image that we will form. w-HAR:4x30, UCI-HAR/UCI-HAPT:33x17, unimib: 25*18, WISDM:27*15\n","img_rows = 27; img_cols = 15\n","#Number of activity labels, w-HAR:8, UCI-HAR:6, UCI-HAPT:12, unimib:9, WISDM:6\n","num_actions = 6\n","#Batch size, epochs, iterations for each CNN\n","batch_size = 128; epochs = 100; n_folds = 10\n","#Specify the number of taotal traning clusters.\n","trained_ucs = [1,2,3,4]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rG9Bna-4qBcj"},"outputs":[],"source":["startTime = datetime.now() # Get the start time of the code \n","#For callbacks logs\n","class TimeHistory(keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.epoch_time_start = time.time()\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cAQG7MAWlmf"},"outputs":[],"source":["from keras.utils import np_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5_gtGrMqHRX"},"outputs":[],"source":["# for trained_uc in trained_ucs:\n","#     #Specify output folder\n","\n","# Specify Cluster\n","trained_uc = 1\n","\n","output_path = 'CNN/WISDM_UC_k_means' + '/trained_with_user_' + str(trained_uc)\n","if not os.path.exists(output_path):\n","\tos.makedirs(output_path)\n","\t#load the features and the labels. 60% train, 20% xval, 20% test\n","df_features_train = pd.read_csv('WISDM_UC_k_means' + '/train_data_' + str(featurenums) + '_v1_uc_' + str(trained_uc) +'.csv', header=None)\n","df_labels_train = pd.read_csv('WISDM_UC_k_means' + '/train_labels_' + str(featurenums) + '_v1_uc_' + str(trained_uc) +'.csv', header=None)\n","\t\t\n","df_features_test = pd.read_csv('WISDM_UC_k_means' +'/test_data_' + str(featurenums) + '_v1_uc_' + str(trained_uc) +'.csv', header=None)\n","df_labels_test = pd.read_csv('WISDM_UC_k_means' +'/test_labels_' + str(featurenums) + '_v1_uc_' + str(trained_uc) +'.csv', header=None)   \n","\t\t\n","df_features_xval = pd.read_csv('WISDM_UC_k_means'+'/xval_data_' + str(featurenums) + '_v1_uc_' + str(trained_uc) +'.csv', header=None)\n","df_labels_xval = pd.read_csv('WISDM_UC_k_means'+'/xval_labels_' + str(featurenums) + '_v1_uc_' + str(trained_uc) +'.csv', header=None)  \n","\n","# Get data for training and test\n","data_train = df_features_train.to_numpy()\n","labels_train = df_labels_train.to_numpy()\n","labels_train = labels_train - 1\n","labels_train = labels_train.ravel()\n","labels_orig_train = labels_train\n","\n","# Extract test data\n","data_test = df_features_test.to_numpy()\n","labels_test = df_labels_test.to_numpy()\n","labels_test = labels_test - 1\n","labels_test = labels_test.ravel()\n","labels_orig_test = labels_test\n","\n","# Extract xval data\n","data_xval = df_features_xval.to_numpy()\n","labels_xval = df_labels_xval.to_numpy()\n","labels_xval = labels_xval - 1\n","labels_xval = labels_xval.ravel()\n","labels_orig_xval = labels_xval\n","\n","# Convert labels\n","labels_train = keras.utils.np_utils.to_categorical(labels_train, num_actions)\n","labels_test = keras.utils.np_utils.to_categorical(labels_test, num_actions)\n","labels_xval = keras.utils.np_utils.to_categorical(labels_xval, num_actions)\n","\n","# \t#for cutting some of the features\n","# \tdata_train = data_train[:,0:450]\n","# \tdata_test = data_test[:,0:450]\n","# \tdata_xval = data_xval[:,0:450]\n","\n","# reshape the input \n","data_train_shaped = data_train.reshape(data_train.shape[0], img_rows, img_cols,1)\n","data_test_shaped = data_test.reshape(data_test.shape[0], img_rows, img_cols,1)\n","data_xval_shaped = data_xval.reshape(data_xval.shape[0], img_rows, img_cols,1)\n","input_shape = (img_rows, img_cols,1)\n","\n","\n","x_train = data_train_shaped\n","y_train = labels_train\n","x_test = data_test_shaped\n","y_test = labels_test\n","x_xval = data_xval_shaped\n","y_xval = labels_xval\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_xval = x_xval.astype('float32')\n","\n","\n","hist = History()\n","callbacks_list = [hist]\n","time_callback = TimeHistory()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNMja31NXBHz"},"outputs":[],"source":["import tensorflow as tf "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122050,"status":"ok","timestamp":1663618828175,"user":{"displayName":"BIJESH PATEL VACHANNI","userId":"06730810590456956092"},"user_tz":300},"id":"85mUQMVET9JK","outputId":"95665c06-0a0f-4231-bb99-c7184c7da629"},"outputs":[{"name":"stdout","output_type":"stream","text":["44/44 [==============================] - 1s 12ms/step - loss: 1.0408 - categorical_accuracy: 0.6715\n","train accuracy =  0.6714593768119812\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.0418 - categorical_accuracy: 0.6492\n","train accuracy =  0.6491732597351074\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 0.9336 - categorical_accuracy: 0.6477\n","train accuracy =  0.6477354168891907\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.1095 - categorical_accuracy: 0.6441\n","train accuracy =  0.644140899181366\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.1116 - categorical_accuracy: 0.6528\n","train accuracy =  0.6527677774429321\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.1579 - categorical_accuracy: 0.6664\n","train accuracy =  0.6664270162582397\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.1609 - categorical_accuracy: 0.6671\n","train accuracy =  0.6671459674835205\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 0.9745 - categorical_accuracy: 0.6298\n","train accuracy =  0.6297627687454224\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.2466 - categorical_accuracy: 0.6506\n","train accuracy =  0.6506110429763794\n","Executed code\n","44/44 [==============================] - 1s 12ms/step - loss: 1.1607 - categorical_accuracy: 0.6621\n","train accuracy =  0.662113606929779\n","Executed code\n"]}],"source":["for i in range(0,n_folds):\n","\t# compile the CNN\n","\tmodel = Sequential()\n","\tmodel.add(Conv2D(32, kernel_size=(1, 1),\n","\t\t\t\t\t\tactivation='relu',\n","\t\t\t\t\t\tinput_shape=input_shape))\n","\tmodel.add(Conv2D(64, (3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D(pool_size=(2, 2)))#2,2\n","\tmodel.add(Dropout(0.25))\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(128, activation='relu'))\n","\tmodel.add(Dropout(0.5))\n","\tmodel.add(Dense(num_actions, activation='softmax'))\n","\tmodel.compile(loss=keras.losses.categorical_crossentropy,\n","\t\t\t\t\toptimizer=tf.keras.optimizers.Adadelta(),\n","\t\t\t\t\tmetrics=['categorical_accuracy'])\n","\t\n","\t\t\t#Log for loss and accuracy\n","\tfilename_log = output_path + '/training_with_{0}_iter_{1}.log'.format(trained_uc,i)\n","\tif (i != 0):\n","\t\tdel callbacks_list[-1]\n","\tcsv_logger = CSVLogger(filename_log)\n","\tcallbacks_list.append(csv_logger)\n","\t\n","\t\n","\t\n","\thistory1 = model.fit(x_train, y_train,\n","\t\t\t\tbatch_size=batch_size,\n","\t\t\t\tepochs=epochs,\n","\t\t\t\tverbose=0,\n","\t\t\t\tvalidation_data=(x_xval, y_xval), callbacks=[csv_logger, time_callback])\n","\tscore_train = model.evaluate(x_train, y_train,verbose = 1)\n","\tprint('train accuracy = ', score_train[1])\n","\t\t\t#Log for training time\n","\ttime_log = output_path + '/training_time_with_{0}_iter_{1}.txt'.format(trained_uc,i)\n","\ttime_callback_list = time_callback.times\n","\tnp.savetxt(time_log, time_callback_list,fmt='%f1') \n","\tprint(\"Executed code\")\n","\t\t\t#Save the model\n","\tmodel.save(output_path + '/model_'+ str(featurenums) +'_train_with_user_' + str(trained_uc) + \\\n","\t\t\t\t\t'_iter_' + str(i))\n","\n","del callbacks_list[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eaQ1E8t6aeW6"},"outputs":[],"source":["'''\n","doing main testing.\n","''' \n","#Testing all UCs accuracy starts here\n","#UCs to be tested\n","tuned_ucs = [1,2,3,4] \n","#Initialize the accuracy array\n","result_acc_baseline_all = np.ones((4,4))\n","result_acc_baseline_test = np.ones((4,4))\t"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wuvKktJHqSlk"},"outputs":[],"source":["# for tuned_uc in tuned_ucs:\n","#     #load the data and labels. \n","\n","# load Cluster\n","tuned_uc = 1\n","\n","df_features_test = pd.read_csv('WISDM_UC_k_means' +'/test_data_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\n","df_labels_test = pd.read_csv('WISDM_UC_k_means' + '/test_labels_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)  \n","df_features_all = pd.read_csv('WISDM_UC_k_means' + '/data_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\n","df_labels_all = pd.read_csv('WISDM_UC_k_means' + '/labels_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\t\n","\n","\n","# Extract test data\n","data_test = df_features_test.to_numpy()\n","labels_test = df_labels_test.to_numpy()\n","labels_test = labels_test - 1\n","labels_test = labels_test.ravel()\n","labels_orig_test = labels_test\n","\n","# Extract all data\n","data_all = df_features_all.to_numpy()\n","labels_all = df_labels_all.to_numpy()\n","labels_all = labels_all - 1\n","labels_all = labels_all.ravel()\n","labels_orig_all = labels_all\n","\n","\n","# Convert labels\n","labels_test = keras.utils.np_utils.to_categorical(labels_test, num_actions)\n","labels_all = keras.utils.np_utils.to_categorical(labels_all, num_actions)\n","\n","# \t#for cutting some of the features\n","# \tdata_test = data_test[:,0:450]\n","# \tdata_all = data_all[:,0:450]\n","\n","# reshape the input \n","data_test_shaped = data_test.reshape(data_test.shape[0], img_rows, img_cols,1)\n","data_all_shaped = data_all.reshape(data_all.shape[0], img_rows, img_cols,1)\n","\n","\n","\n","x_test = data_test_shaped\n","y_test = labels_test\n","x_all = data_all_shaped\n","y_all = labels_all\n","\n","x_test = x_test.astype('float32')\n","x_all = x_all.astype('float32')\n","\t\n","\t\n","# for trained_uc in trained_ucs:\n","\n","# select trained Cluster\n","trained_uc = 1\n","\n","result_acc_baseline_all_temp = []\n","result_acc_baseline_test_temp = []\n","\n","for i in range(0,n_folds):\n","\t#load the trained model\n","\tmodel_path = 'CNN/WISDM_UC_k_means' + '/trained_with_user_'+ str(trained_uc)\\\n","+'/model_'+ str(featurenums) +'_train_with_user_' + str(trained_uc) + '_iter_' + str(i)\n","\tmodel = load_model(model_path)\n","\t\t\t\t#testing\n","\tscore_baseline_test = model.evaluate(x_test,y_test,verbose=0)\n","\tscore_baseline_all = model.evaluate(x_all,y_all,verbose=0)\n","\tresult_acc_baseline_test_temp.append(score_baseline_test[1])\n","\tresult_acc_baseline_all_temp.append(score_baseline_all[1])\n","\n","result_acc_baseline_test[trained_uc-1][tuned_uc-1] = np.mean(result_acc_baseline_test_temp)\n","result_acc_baseline_all[trained_uc-1][tuned_uc-1] = np.mean(result_acc_baseline_all_temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vnrUiBc2qeJ5"},"outputs":[],"source":["#output the accuracy\t\n","output_path = \"CNN/WISDM_UC_k_means/Accuracy\"\n","if not os.path.exists(output_path):\n","\tos.makedirs(output_path)\n","output_filename = output_path + \"/result_{0}_acc_baseline_test_UCs\".format(featurenums)\n","np.save(output_filename + \".npy\", result_acc_baseline_test)\n","np.savetxt(output_filename + \".txt\", result_acc_baseline_test,fmt='%f1')\t\n","output_filename = output_path + \"/result_{0}_acc_baseline_all_UCs\".format(featurenums)\n","np.save(output_filename + \".npy\", result_acc_baseline_all)\n","np.savetxt(output_filename + \".txt\", result_acc_baseline_all,fmt='%f1')\t\n","\t"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwkYKf4Aqhpi"},"outputs":[],"source":["'''\n","doing fine tuning and testing.\n","'''  \n","#Specify the number of the last trainable layers. 1 means only train the last FC layer, 3 means only train the last 2 FC layers. We skipped 2 because the last second layer is just the dropout layer which doesn't affect the result.\n","layers_trainables = [1,3]\n","#initialize the array\n","result_acc_test = np.ones((4,4))\n","\n","for layers_trainable in layers_trainables:\n","\tfor tuned_uc in tuned_ucs:\n","\t\t\n","        #load features and labels.\n","\t\tdf_features_train = pd.read_csv('WISDM_UC_k_means' + '/train_data_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\n","\t\tdf_labels_train = pd.read_csv('WISDM_UC_k_means' + '/train_labels_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\n","\t\t\t\t\n","\t\tdf_features_test = pd.read_csv('WISDM_UC_k_means' + '/test_data_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\n","\t\tdf_labels_test = pd.read_csv('WISDM_UC_k_means' + '/test_labels_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)   \n","\t\t\t\t\n","\t\tdf_features_xval = pd.read_csv('WISDM_UC_k_means' + '/xval_data_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)\n","\t\tdf_labels_xval = pd.read_csv('WISDM_UC_k_means' + '/xval_labels_' + str(featurenums) + '_v1_uc_' + str(tuned_uc) +'.csv', header=None)  \n","\t\t\n","\t\t\n","\t\t\n","\t\t# Get data for training and test\n","\t\tdata_train = df_features_train.to_numpy()\n","\t\tlabels_train = df_labels_train.to_numpy()\n","\t\tlabels_train = labels_train - 1\n","\t\tlabels_train = labels_train.ravel()\n","\t\tlabels_orig_train = labels_train\n","\t\t\n","\t\t# Extract test data\n","\t\tdata_test = df_features_test.to_numpy()\n","\t\tlabels_test = df_labels_test.to_numpy()\n","\t\tlabels_test = labels_test - 1\n","\t\tlabels_test = labels_test.ravel()\n","\t\tlabels_orig_test = labels_test\n","\t\t\n","\t\t# Extract xval data\n","\t\tdata_xval = df_features_xval.to_numpy()\n","\t\tlabels_xval = df_labels_xval.to_numpy()\n","\t\tlabels_xval = labels_xval - 1\n","\t\tlabels_xval = labels_xval.ravel()\n","\t\tlabels_orig_xval = labels_xval\n","\t\t\n","\n","\t\t# Convert labels\n","\t\tlabels_train = keras.utils.to_categorical(labels_train, num_actions)\n","\t\tlabels_test = keras.utils.to_categorical(labels_test, num_actions)\n","\t\tlabels_xval = keras.utils.to_categorical(labels_xval, num_actions)\n","\t\t\n","\n","\n","# \t\t#for cutting some of the features\n","# \t\tdata_train = data_train[:,0:450]\n","# \t\tdata_test = data_test[:,0:450]\n","# \t\tdata_xval = data_xval[:,0:450]\n","\n","\t\t# reshape the input \n","\t\tdata_train_shaped = data_train.reshape(data_train.shape[0], img_rows, img_cols,1)\n","\t\tdata_test_shaped = data_test.reshape(data_test.shape[0], img_rows, img_cols,1)\n","\t\tdata_xval_shaped = data_xval.reshape(data_xval.shape[0], img_rows, img_cols,1)\n","\t\tinput_shape = (img_rows, img_cols,1)\n","\t\t\n","\n","\t\t\n","\t\tx_train = data_train_shaped\n","\t\ty_train = labels_train\n","\t\tx_test = data_test_shaped\n","\t\ty_test = labels_test\n","\t\tx_xval = data_xval_shaped\n","\t\ty_xval = labels_xval\n","        \n","\t\tx_train = x_train.astype('float32')\n","\t\tx_test = x_test.astype('float32')\n","\t\tx_xval = x_xval.astype('float32')\n","\t\t\n","\n","\t\t\n","\t\tfor trained_uc in trained_ucs:\n","            #Set the output folder\n","\t\t\toutput_folder = 'CNN/WISDM_UC_k_means'  +'/trained_with_user_{0}/last{1}layer_trainable'.format(trained_uc, layers_trainable)\n","\t\t\tif not os.path.exists(output_folder):\n","\t\t\t\tos.makedirs(output_folder)\n","\t\t\thist = History()\n","\t\t\tcallbacks_list = [hist]\n","\t\t\ttime_callback = TimeHistory()\n","\t\t\tresult_acc_test_temp = []\n","\t\t\tfor i in range(0,n_folds):\n","\t\n","\t\t\t\t\n","\t\t\t\t# Load the baseline CNN models\n","\t\t\t\ttrained_model_path = 'CNN/WISDM_UC_k_means/' + '/trained_with_user_{0}/model_{1}_train_with_user_{2}_iter_{3}'.format(trained_uc, featurenums, trained_uc,i)\n","\t\t\t\tmodel = load_model(trained_model_path)\n","\t\t\t\t\n","\t\t\n","\t\t\t\t\t\n","\t\t\t\t# freeze all layers except the deeper layers\n","\t\t\t\tfor layer in model.layers[:-layers_trainable]:\n","\t\t\t\t\tlayer.trainable = False\t\t\t\t\n","\t\t\t\tmodel.compile(loss=keras.losses.categorical_crossentropy,\\\n","\t\t\t\t  optimizer=keras.optimizers.Adadelta(), metrics=['categorical_accuracy'])\n","\t\t\t\t\t\t\t\t   \n","\t\t\t\t# Print the trainable status\n","\t\t\t\tfor layer in model.layers:\n","\t\t\t\t\tprint(layer, layer.trainable)\n","\t\t\t\t\n","\t\t\t\t# Print model summary\n","\t\t\t\tmodel.summary()    \n","\t\t\t\t\n","\t\t\t\t#Log for accuracy and Loss\n","\t\t\t\tfilename_log = output_folder + '/training_tune_with_user_{0}_iter_{1}_last{2}layer_trainable.log'.format(tuned_uc,i,layers_trainable)\n","\t\t\t\tif (i != 0):\n","\t\t\t\t\tdel callbacks_list[-1]\n","\t\t\t\tcsv_logger = CSVLogger(filename_log)\n","\t\t\t\tcallbacks_list.append(csv_logger)\n","\t\t\t\t\n","\t\t\t\thistory = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0,validation_data=(x_xval, y_xval), callbacks=[csv_logger, time_callback])\n","\t\t\t\tscore_train =model.evaluate(x_train, y_train, verbose=1)\n","\t\t\t\tprint('train accuracy is ', score_train[1])\n","\t\t\t\t#Log for time\n","\t\t\t\ttime_log = output_folder + '/training_time_tune_with_user_{0}_iter_{1}_last{2}layer_trainable'.format(tuned_uc,i,layers_trainable)\n","\t\t\t\ttime_callback_list = time_callback.times\n","                #save the time log\n","\t\t\t\tnp.save(time_log + \".npy\", time_callback_list)\n","\t\t\t\tnp.savetxt(time_log + \".txt\", time_callback_list,fmt='%f1')\n","                #save the fine-tuned CNN model\n","\t\t\t\tfilename = output_folder + '/model_{0}_train_with_user_{1}_tune_with_user_{2}_iter_{3}_last{4}layer_trainable'\\\n","\t\t\t\t\t.format(featurenums, trained_uc, tuned_uc, i, layers_trainable)\n","\t\t\t\tmodel.save(filename)\n","\t\t\t\t\n","\t\t\t\tscore_test = model.evaluate(x_test, y_test, verbose=0)\n","\t\t\t\tscore_xval = model.evaluate(x_xval, y_xval, verbose = 0)\n","\t\t\t\tresult_acc_test_temp.append(score_test[1])\n","\t\t\t\tprint(\"Trained_uc =\", trained_uc)\n","\t\t\t\tprint(\"Tuned_uc =\", tuned_uc)\n","\t\t\t\tprint(\"Running Fold\", i+1, \"/\", n_folds)\n","\t\t\t\tprint('Test accuracy:', score_test[1])\n","\t\t\t\tprint('Xval accuracy:', score_xval[1]) \n","\t\t\tdel callbacks_list[-1]\n","\t\t\tresult_acc_test[trained_uc-1][tuned_uc-1] = np.mean(result_acc_test_temp)\n","\t\n","\t\t\t\t\n","\t\n","\t#Export the Accuracy\t\n","\toutput_path = \"CNN/WISDM_UC_k_means\" + \"/Accuracy\"\n","\toutput_filename = output_path + \"/result_{0}_acc_test_UCs_last{1}layer_trainable\".format(featurenums, layers_trainable)\n","\tnp.save(output_filename + \".npy\", result_acc_test)\n","\tnp.savetxt(output_filename + \".txt\", result_acc_test,fmt='%f1')\t\n","\n","print('The entire code running time is ', datetime.now() - startTime)\t"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1L64C89wfQaodRsVnMRN9weOnf_h2fdyJ","timestamp":1663788500878}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}