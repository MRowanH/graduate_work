{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1WRfAxn1gPp1BW-wVr6YFgKqrvicP_9wm","authorship_tag":"ABX9TyNPaX7ggmUv5zh4/pUNgIq0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Resources/Notices\n","\n","Dataset used: https://www.kaggle.com/datasets/hashbanger/skin-lesion-segmentation?resource=download\n","\n","Guide (similar task): https://www.youtube.com/watch?v=IHq1t7NxS8k&t=2807s\n","\n","Note: This dataset comes with the binary mask neccessary for training. The creation of such masks for the skin burn segmentation will need to be completed to bridge the previous parts of this project to this part of the project."],"metadata":{"id":"1VbcOYXONsbE"}},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"P8lHWKrRNheI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"bbIf2YgJMpDH","executionInfo":{"status":"ok","timestamp":1669998465269,"user_tz":360,"elapsed":5045,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"outputs":[],"source":["import albumentations as A\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms.functional as TF\n","\n","from albumentations.pytorch import ToTensorV2\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm"]},{"cell_type":"code","source":["model = None"],"metadata":{"id":"Ts40eIqnPraF","executionInfo":{"status":"ok","timestamp":1669998465493,"user_tz":360,"elapsed":19,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"ghsOdB3uNfpM"}},{"cell_type":"markdown","source":["Code in this section is a modified version of the code found at: \n","\n","https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/image_segmentation/semantic_segmentation_unet"],"metadata":{"id":"4jV51qvsT25c"}},{"cell_type":"markdown","source":["## utils.py"],"metadata":{"id":"ZyRBdHt-MzPD"}},{"cell_type":"code","source":["def get_test_loader(\n","    test_dir,\n","    test_maskdir,\n","    batch_size,\n","    test_transform,\n","    num_workers=4,\n","    pin_memory=True,\n","):\n","\n","    test_ds = CarvanaDataset(\n","        image_dir=test_dir,\n","        mask_dir=test_maskdir,\n","        transform=test_transform,\n","    )\n","\n","    test_loader = DataLoader(\n","        test_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=False,\n","    )\n","\n","    return test_loader"],"metadata":{"id":"5fpXZjzRgzk5","executionInfo":{"status":"ok","timestamp":1669998465494,"user_tz":360,"elapsed":17,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","def load_checkpoint(checkpoint, model):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","def get_loaders(\n","    train_dir,\n","    train_maskdir,\n","    val_dir,\n","    val_maskdir,\n","    batch_size,\n","    train_transform,\n","    val_transform,\n","    num_workers=4,\n","    pin_memory=True,\n","):\n","    train_ds = CarvanaDataset(\n","        image_dir=train_dir,\n","        mask_dir=train_maskdir,\n","        transform=train_transform,\n","    )\n","\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=True,\n","    )\n","\n","    val_ds = CarvanaDataset(\n","        image_dir=val_dir,\n","        mask_dir=val_maskdir,\n","        transform=val_transform,\n","    )\n","\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=False,\n","    )\n","\n","    return train_loader, val_loader\n","\n","def check_accuracy(loader, model, device=\"cuda\", train=True):\n","    num_correct = 0\n","    num_pixels = 0\n","    dice_score = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device)\n","            y = y.to(device).unsqueeze(1)\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","            num_correct += (preds == y).sum()\n","            num_pixels += torch.numel(preds)\n","            dice_score += (2 * (preds * y).sum()) / (\n","                (preds + y).sum() + 1e-8\n","            )\n","\n","    print(\n","        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n","    )\n","    print(f\"Dice score: {dice_score/len(loader)}\")\n","    if train:\n","        model.train()\n","\n","    return num_correct, num_pixels, dice_score\n","\n","def save_predictions_as_imgs(\n","    loader, model, folder=\"saved_images/\", device=\"cuda\"\n","):\n","    model.eval()\n","    for idx, (x, y) in enumerate(loader):\n","        x = x.to(device=device)\n","        with torch.no_grad():\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","        torchvision.utils.save_image(\n","            preds, f\"{folder}pred_{idx}.png\"\n","        )\n","        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n","\n","    model.train()"],"metadata":{"id":"OmmJN07SMzJG","executionInfo":{"status":"ok","timestamp":1669998465495,"user_tz":360,"elapsed":16,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## dataset.py"],"metadata":{"id":"aE1c6cqGM3Dl"}},{"cell_type":"code","source":["class CarvanaDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.images = os.listdir(image_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.image_dir, self.images[index])\n","        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\"imgx\", \"imgy\")) #.replace(\".jpg\", \"_mask.gif\"))\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n","        mask[mask == 255.0] = 1.0\n","\n","        if self.transform is not None:\n","            augmentations = self.transform(image=image, mask=mask)\n","            image = augmentations[\"image\"]\n","            mask = augmentations[\"mask\"]\n","\n","        return image, mask"],"metadata":{"id":"vF0ipOtiM5km","executionInfo":{"status":"ok","timestamp":1669998465496,"user_tz":360,"elapsed":16,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## model.py"],"metadata":{"id":"9_M0mb1IM5zv"}},{"cell_type":"code","source":["class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class UNET(nn.Module):\n","    def __init__(\n","            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n","    ):\n","        super(UNET, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down part of UNET\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up part of UNET\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(\n","                    feature*2, feature, kernel_size=2, stride=2,\n","                )\n","            )\n","            self.ups.append(DoubleConv(feature*2, feature))\n","\n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","        skip_connections = skip_connections[::-1]\n","\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx//2]\n","\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx+1](concat_skip)\n","\n","        return self.final_conv(x)\n","\n","def test():\n","    x = torch.randn((3, 1, 161, 161))\n","    model = UNET(in_channels=1, out_channels=1)\n","    preds = model(x)\n","    print(preds.shape, x.shape)\n","    assert preds.shape == x.shape"],"metadata":{"id":"La2yM2NAM7j2","executionInfo":{"status":"ok","timestamp":1669998465497,"user_tz":360,"elapsed":16,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## train.py"],"metadata":{"id":"DlfSCgJbM73B"}},{"cell_type":"code","source":["def test_fn(loader, model):\n","    loop = tqdm(loader)\n","    preds = []\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=DEVICE)\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            preds.append(predictions)\n","\n","    return preds"],"metadata":{"id":"lzrt6a3kf7Rn","executionInfo":{"status":"ok","timestamp":1669998465498,"user_tz":360,"elapsed":16,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train_fn(loader, model, optimizer, loss_fn, scaler):\n","    loop = tqdm(loader)\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=DEVICE)\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # update tqdm loop\n","        loop.set_postfix(loss=loss.item())\n","\n","\n","def main():\n","    train_transform = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Rotate(limit=35, p=1.0),\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.1),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    val_transforms = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n","    loss_fn = nn.BCEWithLogitsLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","    train_loader, val_loader = get_loaders(\n","        TRAIN_IMG_DIR,\n","        TRAIN_MASK_DIR,\n","        VAL_IMG_DIR,\n","        VAL_MASK_DIR,\n","        BATCH_SIZE,\n","        train_transform,\n","        val_transforms,\n","        NUM_WORKERS,\n","        PIN_MEMORY,\n","    )\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n","\n","\n","    num_correct, num_pixels, dice_score = check_accuracy(val_loader, model, device=DEVICE)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","\n","        # save model\n","        checkpoint = {\n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\":optimizer.state_dict(),\n","        }\n","        save_checkpoint(checkpoint)\n","\n","        # check accuracy\n","        check_accuracy(val_loader, model, device=DEVICE)\n","\n","        # print some examples to a folder\n","        save_predictions_as_imgs(\n","            val_loader, model, folder=SAVE_DIR, device=DEVICE\n","        )\n","\n","\n","    return  model, loss_fn, optimizer, scaler, train_transform, val_transforms, train_loader, val_loader, num_correct, num_pixels, dice_score"],"metadata":{"id":"qm6k1x6kM-N2","executionInfo":{"status":"ok","timestamp":1669998465499,"user_tz":360,"elapsed":15,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"U48ZdIAAlomT"}},{"cell_type":"markdown","source":["## Hyperparameters"],"metadata":{"id":"b0bdtBxeRcDc"}},{"cell_type":"code","source":["# Directories\n","data_dir = \"/content/drive/MyDrive/Classes/CSCE 5280 AI for Wearables/P3 Skin Graft Application/skin lesion/\"   # Mica\n","TRAIN_IMG_DIR = data_dir + \"trainx/\" # \"data/train_images/\"\n","TRAIN_MASK_DIR = data_dir + \"trainy/\" # \"data/train_masks/\" \n","VAL_IMG_DIR = data_dir + \"validationx/\" # \"data/val_images/\"\n","VAL_MASK_DIR = data_dir + \"validationy/\" # \"data/val_masks/\"\n","TEST_IMG_DIR = data_dir + \"testx/\"\n","TEST_MASK_DIR = data_dir + \"testy/\"\n","SAVE_DIR = data_dir + \"saved_images/\"\n","SAVE_DIR_TEST = data_dir + \"test_preds/\"\n","PICKLE_DIR = \"/\".join(data_dir.split(\"/\")[:-2]) + \"/\"\n","\n","# Hyperparameters etc.\n","LEARNING_RATE = 1e-4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 10\n","NUM_WORKERS = 2\n","IMAGE_HEIGHT = 192 # 160  # 1280 originally\n","IMAGE_WIDTH = 256 # 240  # 1918 originally\n","PIN_MEMORY = True\n","LOAD_MODEL = False"],"metadata":{"id":"7t7zkJ4QNFWt","executionInfo":{"status":"ok","timestamp":1669998466147,"user_tz":360,"elapsed":233,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Train Model"],"metadata":{"id":"D6eds9c4RfDY"}},{"cell_type":"code","source":["test()"],"metadata":{"id":"QLdeUhWsNGzh","executionInfo":{"status":"ok","timestamp":1669998468729,"user_tz":360,"elapsed":2591,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c32d1c91-e2fa-4260-8041-5c14898660fd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 1, 161, 161]) torch.Size([3, 1, 161, 161])\n"]}]},{"cell_type":"code","source":["# Best loss at ~epoch=1, re-train\n","NUM_EPOCHS = 1\n","model, loss_fn, optimizer, scaler, train_transform, val_transforms, train_loader, val_loader, num_correct, num_pixels, dice_score = main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1t0zMQAvVpUU","executionInfo":{"status":"ok","timestamp":1669999142152,"user_tz":360,"elapsed":673434,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}},"outputId":"0ec92ec0-dc47-4814-e8a7-5b9bd7102281"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 1144464/7372800 with acc 15.52\n","Dice score: 1.7151132822036743\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 125/125 [10:05<00:00,  4.84s/it, loss=-46.3]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","Got 5712475/7372800 with acc 77.48\n","Dice score: 1.5362615585327148\n"]}]},{"cell_type":"markdown","source":["## Test Model"],"metadata":{"id":"cGgG8B_zRg8r"}},{"cell_type":"code","source":["# Load from file for testing of previous trains\n","if model is None:\n","    with open(PICKLE_DIR + \"model.pickle\", \"rb\") as file:\n","        model = pickle.load(file)"],"metadata":{"id":"LES6XUPMloGa","executionInfo":{"status":"ok","timestamp":1669999142153,"user_tz":360,"elapsed":18,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["test_transforms = A.Compose(\n","    [\n","        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","        A.Normalize(\n","            mean=[0.0, 0.0, 0.0],\n","            std=[1.0, 1.0, 1.0],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ],\n",")\n","test_loader = get_test_loader(\n","    TEST_IMG_DIR,\n","    TEST_MASK_DIR,\n","    BATCH_SIZE,\n","    test_transforms,\n","    NUM_WORKERS,\n","    PIN_MEMORY,\n",")\n","\n","num_correct, num_pixels, dice_score = check_accuracy(test_loader, model, device=DEVICE)\n","save_predictions_as_imgs(test_loader, model, folder=data_dir + \"test_preds/\", device=DEVICE)"],"metadata":{"id":"f0TC_b7fh8-d","executionInfo":{"status":"ok","timestamp":1669999278750,"user_tz":360,"elapsed":136612,"user":{"displayName":"Mica Haney","userId":"02567847060328523003"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6aa8434-9ca7-4e5a-d63f-817c9d2f8b0c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 21178095/29491200 with acc 71.81\n","Dice score: 1.4927130937576294\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Mn0mwHjLtdOK"},"execution_count":null,"outputs":[]}]}